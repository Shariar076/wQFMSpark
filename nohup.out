21/11/09 04:11:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/11/09 04:11:41 INFO SparkContext: Running Spark version 3.1.2
21/11/09 04:11:41 INFO ResourceUtils: ==============================================================
21/11/09 04:11:41 INFO ResourceUtils: No custom resources configured for spark.driver.
21/11/09 04:11:41 INFO ResourceUtils: ==============================================================
21/11/09 04:11:41 INFO SparkContext: Submitted application: wQFMSpark
21/11/09 04:11:41 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 40960, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/11/09 04:11:41 INFO ResourceProfile: Limiting resource is cpu
21/11/09 04:11:41 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/11/09 04:11:41 INFO SecurityManager: Changing view acls to: kab076
21/11/09 04:11:41 INFO SecurityManager: Changing modify acls to: kab076
21/11/09 04:11:41 INFO SecurityManager: Changing view acls groups to: 
21/11/09 04:11:41 INFO SecurityManager: Changing modify acls groups to: 
21/11/09 04:11:41 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(kab076); groups with view permissions: Set(); users  with modify permissions: Set(kab076); groups with modify permissions: Set()
21/11/09 04:11:41 INFO Utils: Successfully started service 'sparkDriver' on port 42555.
21/11/09 04:11:41 INFO SparkEnv: Registering MapOutputTracker
21/11/09 04:11:41 INFO SparkEnv: Registering BlockManagerMaster
21/11/09 04:11:41 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/11/09 04:11:41 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/11/09 04:11:41 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/11/09 04:11:41 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-c4a49525-7bab-4834-95c7-1dcaa14addbb
21/11/09 04:11:42 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/11/09 04:11:42 INFO SparkEnv: Registering OutputCommitCoordinator
21/11/09 04:11:42 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/11/09 04:11:42 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://ms0819.utah.cloudlab.us:4040
21/11/09 04:11:42 INFO SparkContext: Added JAR file:/users/kab076/wQFMSpark/./target/wQFMSpark-1.0-SNAPSHOT-jar-with-dependencies.jar at spark://ms0819.utah.cloudlab.us:42555/jars/wQFMSpark-1.0-SNAPSHOT-jar-with-dependencies.jar with timestamp 1636456301358
21/11/09 04:11:42 INFO SparkContext: Added file file:///users/kab076/wQFMSpark/triplets.soda2103 at spark://ms0819.utah.cloudlab.us:42555/files/triplets.soda2103 with timestamp 1636456301358
21/11/09 04:11:42 INFO Utils: Copying /users/kab076/wQFMSpark/triplets.soda2103 to /tmp/spark-7d00f7ce-20bf-4257-8f8d-ef3e2082fd9f/userFiles-aec7f40f-c93d-4555-9261-2b9a9e4bc093/triplets.soda2103
21/11/09 04:11:42 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://node0:7077...
21/11/09 04:11:42 INFO TransportClientFactory: Successfully created connection to node0/10.10.1.1:7077 after 44 ms (0 ms spent in bootstraps)
21/11/09 04:11:42 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211109041142-0010
21/11/09 04:11:42 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211109041142-0010/0 on worker-20211109002414-128.110.217.44-43329 (128.110.217.44:43329) with 16 core(s)
21/11/09 04:11:42 INFO StandaloneSchedulerBackend: Granted executor ID app-20211109041142-0010/0 on hostPort 128.110.217.44:43329 with 16 core(s), 40.0 GiB RAM
21/11/09 04:11:42 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211109041142-0010/1 on worker-20211109002452-128.110.217.51-42171 (128.110.217.51:42171) with 16 core(s)
21/11/09 04:11:42 INFO StandaloneSchedulerBackend: Granted executor ID app-20211109041142-0010/1 on hostPort 128.110.217.51:42171 with 16 core(s), 40.0 GiB RAM
21/11/09 04:11:42 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211109041142-0010/2 on worker-20211109002436-128.110.217.52-35535 (128.110.217.52:35535) with 16 core(s)
21/11/09 04:11:42 INFO StandaloneSchedulerBackend: Granted executor ID app-20211109041142-0010/2 on hostPort 128.110.217.52:35535 with 16 core(s), 40.0 GiB RAM
21/11/09 04:11:42 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33155.
21/11/09 04:11:42 INFO NettyBlockTransferService: Server created on ms0819.utah.cloudlab.us:33155
21/11/09 04:11:42 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/11/09 04:11:42 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, ms0819.utah.cloudlab.us, 33155, None)
21/11/09 04:11:42 INFO BlockManagerMasterEndpoint: Registering block manager ms0819.utah.cloudlab.us:33155 with 398.7 MiB RAM, BlockManagerId(driver, ms0819.utah.cloudlab.us, 33155, None)
21/11/09 04:11:42 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, ms0819.utah.cloudlab.us, 33155, None)
21/11/09 04:11:42 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, ms0819.utah.cloudlab.us, 33155, None)
21/11/09 04:11:42 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211109041142-0010/1 is now RUNNING
21/11/09 04:11:42 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211109041142-0010/2 is now RUNNING
21/11/09 04:11:42 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211109041142-0010/0 is now RUNNING
21/11/09 04:11:43 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
21/11/09 04:11:43 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
Input file consists of gene trees ... generating weighted quartets to file: input/input-weighted-quartets.csv
Generation of weighted quartets completed.
================= **** ========== Running wQFM on Spark ============== **** ====================
Final Taxa Table: TaxaTable{TAXA_COUNT=37,
 TAXA_LIST=[BOS, TAR, MAC, MON, OTO, ECH, HOM, LOX, PON, ERI, VIC, ORN, RAT, CAV, GOR, SUS, DIP, FEL, TUR, TUP, CAL, ORY, MUS, GAL, MIC, PAN, DAS, CAN, EQU, SPE, CHO, SOR, PTE, MYO, OCH, PRO, NEW],
 TAXA_PARTITION_LIST Size=178}
+---+-----+
|tag|count|
+---+-----+
|112|8718 |
|113|6239 |
|110|2497 |
|89 |39026|
|111|6314 |
|114|1391 |
|88 |75640|
+---+-----+

+-----+-----+---+
|value|count|tag|
+-----+-----+---+
+-----+-----+---+

Number of Partitions by taxaPartition: 7
Number of Data Partitions: 200
21/11/09 04:12:21 ERROR TaskSchedulerImpl: Lost executor 2 on 128.110.217.52: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
21/11/09 04:12:21 WARN TaskSetManager: Lost task 19.0 in stage 21.0 (TID 803) (128.110.217.52 executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
21/11/09 04:12:21 WARN TaskSetManager: Lost task 92.0 in stage 21.0 (TID 806) (128.110.217.52 executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
21/11/09 04:12:21 WARN TaskSetManager: Lost task 19.1 in stage 21.0 (TID 1003) (128.110.217.51 executor 1): FetchFailed(BlockManagerId(2, 128.110.217.52, 32819, None), shuffleId=5, mapIndex=2, mapId=764, reduceId=19, message=
org.apache.spark.shuffle.FetchFailedException: The relative remote executor(Id: 2), which maintains the block data to fetch is dead.
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:770)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:685)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)
	at org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)
	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at scala.collection.convert.Wrappers$IteratorWrapper.hasNext(Wrappers.scala:31)
	at mapper.QuartetToTreeTablePartitionMapper.call(QuartetToTreeTablePartitionMapper.java:24)
	at org.apache.spark.sql.Dataset.$anonfun$mapPartitions$1(Dataset.scala:2820)
	at org.apache.spark.sql.execution.MapPartitionsExec.$anonfun$doExecute$3(objects.scala:195)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.ExecutorDeadException: The relative remote executor(Id: 2), which maintains the block data to fetch is dead.
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:133)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.start(RetryingBlockFetcher.java:133)
	at org.apache.spark.network.netty.NettyBlockTransferService.fetchBlocks(NettyBlockTransferService.scala:143)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.sendRequest(ShuffleBlockFetcherIterator.scala:283)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.send$1(ShuffleBlockFetcherIterator.scala:743)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchUpToMaxBytes(ShuffleBlockFetcherIterator.scala:738)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:552)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:171)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:85)
	at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:212)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	... 23 more

)
21/11/09 04:12:21 WARN TaskSetManager: Lost task 92.1 in stage 21.0 (TID 1002) (128.110.217.44 executor 0): FetchFailed(BlockManagerId(2, 128.110.217.52, 32819, None), shuffleId=5, mapIndex=2, mapId=764, reduceId=92, message=
org.apache.spark.shuffle.FetchFailedException: The relative remote executor(Id: 2), which maintains the block data to fetch is dead.
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:770)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:685)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)
	at org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)
	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at scala.collection.convert.Wrappers$IteratorWrapper.hasNext(Wrappers.scala:31)
	at mapper.QuartetToTreeTablePartitionMapper.call(QuartetToTreeTablePartitionMapper.java:24)
	at org.apache.spark.sql.Dataset.$anonfun$mapPartitions$1(Dataset.scala:2820)
	at org.apache.spark.sql.execution.MapPartitionsExec.$anonfun$doExecute$3(objects.scala:195)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.ExecutorDeadException: The relative remote executor(Id: 2), which maintains the block data to fetch is dead.
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:133)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.start(RetryingBlockFetcher.java:133)
	at org.apache.spark.network.netty.NettyBlockTransferService.fetchBlocks(NettyBlockTransferService.scala:143)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.sendRequest(ShuffleBlockFetcherIterator.scala:283)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.send$1(ShuffleBlockFetcherIterator.scala:743)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchUpToMaxBytes(ShuffleBlockFetcherIterator.scala:738)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:552)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:171)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:85)
	at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:212)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	... 23 more

)
21/11/09 04:12:26 WARN TaskSetManager: Lost task 6.0 in stage 21.1 (TID 1023) (128.110.217.51 executor 1): TaskKilled (Stage finished)
+--------+---+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|support |tag|tree                                                                                                                                                                                          |
+--------+---+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|899000.0|88 |((((LOX,ECH),((DAS,CHO),(GAL,(ORN,(MAC,MON))))),((ERI,SOR),((MYO,PTE),((EQU,(CAN,FEL)),(VIC,(BOS,TUR)))))),((TUP,(OCH,(SPE,(DIP,(RAT,MUS))))),(OTO,(TAR,(CAL,(NEW,(PON,(GOR,(PAN,HOM)))))))));|
|460250.0|89 |((((GAL,(DAS,CHO)),(ECH,(LOX,PRO))),((ERI,SOR),((MYO,PTE),((EQU,FEL),(VIC,(SUS,(BOS,TUR))))))),((TUP,((ORY,OCH),(CAV,(SPE,(DIP,(RAT,MUS)))))),((OTO,MIC),(TAR,(NEW,(PON,(GOR,(PAN,HOM))))))));|
|104625.0|112|(((TUP,(OCH,(CAV,(SPE,(RAT,MUS,DIP))))),(MIC,(CAL,(NEW,(GOR,PAN,HOM,PON))))),((((ORN,GAL),(DAS,CHO)),(ECH,(LOX,PRO))),((ERI,SOR),((MYO,PTE),((EQU,(CAN,FEL)),(VIC,(SUS,(BOS,TUR))))))));      |
|72150.0 |111|(((((DAS,CHO),(LOX,ECH)),(GAL,(MAC,MON))),((SOR,ERI),((PTE,MYO),((FEL,EQU),(VIC,(SUS,(BOS,TUR))))))),((TUP,((ORY,OCH),(CAV,(SPE,(RAT,MUS,DIP))))),((OTO,MIC),(TAR,(GOR,PON,PAN,HOM)))));      |
|70850.0 |113|(((TUP,(ORY,(CAV,RAT,SPE,MUS))),((OTO,MIC),(TAR,(CAL,(NEW,(GOR,PON,HOM)))))),(((ORN,(MAC,MON)),((DAS,CHO),(ECH,(LOX,PRO)))),((SOR,ERI),((PTE,MYO),((SUS,BOS,VIC),(EQU,(CAN,FEL)))))));        |
|28375.0 |110|((((DIP,RAT),(ORY,OCH)),(OTO,(TAR,(NEW,(CAL,(PAN,HOM)))))),((MYO,(CAN,(VIC,TUR))),((ECH,PRO),(GAL,(ORN,(MON,MAC))))));                                                                        |
|15875.0 |114|(((TUP,((SPE,DIP,CAV,MUS),(ORY,OCH))),((TAR,(CAL,(PON,PAN,NEW,GOR))),(MIC,OTO))),((((DAS,CHO),(PRO,LOX)),(GAL,(ORN,(MON,MAC)))),(ERI,SOR,(PTE,((EQU,(CAN,FEL)),(TUR,BOS,SUS))))));            |
+--------+---+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

Total generated trees: 7
Final tree (((TUP,((ORY,OCH),(CAV,(SPE,(DIP,MUS,RAT))))),((OTO,MIC),(CAL,(TAR,(NEW,(PON,(GOR,(PAN,HOM)))))))),((((ORN,GAL),(DAS,CHO)),(ECH,(PRO,LOX))),((ERI,SOR),((MYO,PTE),((EQU,(CAN,FEL)),(VIC,(SUS,(BOS,TUR))))))));
distributedRunTree: (((TUP,((ORY,OCH),(CAV,(SPE,(DIP,MUS,RAT))))),((OTO,MIC),(CAL,(TAR,(NEW,(PON,(GOR,(PAN,HOM)))))))),((((ORN,GAL),(DAS,CHO)),(ECH,(PRO,LOX))),((ERI,SOR),((MYO,PTE),((EQU,(CAN,FEL)),(VIC,(SUS,(BOS,TUR))))))));

Time taken = 30749 ms ==> 0 minutes and 30 seconds.
================= **** ======================== **** ====================
21/11/09 04:23:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/11/09 04:23:28 INFO SparkContext: Running Spark version 3.1.2
21/11/09 04:23:28 INFO ResourceUtils: ==============================================================
21/11/09 04:23:28 INFO ResourceUtils: No custom resources configured for spark.driver.
21/11/09 04:23:28 INFO ResourceUtils: ==============================================================
21/11/09 04:23:28 INFO SparkContext: Submitted application: wQFMSpark
21/11/09 04:23:28 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 40960, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/11/09 04:23:28 INFO ResourceProfile: Limiting resource is cpu
21/11/09 04:23:28 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/11/09 04:23:28 INFO SecurityManager: Changing view acls to: kab076
21/11/09 04:23:28 INFO SecurityManager: Changing modify acls to: kab076
21/11/09 04:23:28 INFO SecurityManager: Changing view acls groups to: 
21/11/09 04:23:28 INFO SecurityManager: Changing modify acls groups to: 
21/11/09 04:23:28 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(kab076); groups with view permissions: Set(); users  with modify permissions: Set(kab076); groups with modify permissions: Set()
21/11/09 04:23:28 INFO Utils: Successfully started service 'sparkDriver' on port 40505.
21/11/09 04:23:28 INFO SparkEnv: Registering MapOutputTracker
21/11/09 04:23:28 INFO SparkEnv: Registering BlockManagerMaster
21/11/09 04:23:28 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/11/09 04:23:28 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/11/09 04:23:28 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/11/09 04:23:28 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-145e852b-c67c-4dea-a802-5807bae06dc1
21/11/09 04:23:28 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/11/09 04:23:28 INFO SparkEnv: Registering OutputCommitCoordinator
21/11/09 04:23:28 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/11/09 04:23:29 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://ms0819.utah.cloudlab.us:4040
21/11/09 04:23:29 INFO SparkContext: Added JAR file:/users/kab076/wQFMSpark/./target/wQFMSpark-1.0-SNAPSHOT-jar-with-dependencies.jar at spark://ms0819.utah.cloudlab.us:40505/jars/wQFMSpark-1.0-SNAPSHOT-jar-with-dependencies.jar with timestamp 1636457008075
21/11/09 04:23:29 INFO SparkContext: Added file file:///users/kab076/wQFMSpark/triplets.soda2103 at spark://ms0819.utah.cloudlab.us:40505/files/triplets.soda2103 with timestamp 1636457008075
21/11/09 04:23:29 INFO Utils: Copying /users/kab076/wQFMSpark/triplets.soda2103 to /tmp/spark-c1c23465-2815-46d6-a6cb-23c15a3afcc8/userFiles-44cbd018-5921-4d18-8d63-e8eb108e8517/triplets.soda2103
21/11/09 04:23:29 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://node0:7077...
21/11/09 04:23:29 INFO TransportClientFactory: Successfully created connection to node0/10.10.1.1:7077 after 43 ms (0 ms spent in bootstraps)
21/11/09 04:23:29 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211109042329-0014
21/11/09 04:23:29 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211109042329-0014/0 on worker-20211109002414-128.110.217.44-43329 (128.110.217.44:43329) with 16 core(s)
21/11/09 04:23:29 INFO StandaloneSchedulerBackend: Granted executor ID app-20211109042329-0014/0 on hostPort 128.110.217.44:43329 with 16 core(s), 40.0 GiB RAM
21/11/09 04:23:29 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211109042329-0014/1 on worker-20211109002452-128.110.217.51-42171 (128.110.217.51:42171) with 16 core(s)
21/11/09 04:23:29 INFO StandaloneSchedulerBackend: Granted executor ID app-20211109042329-0014/1 on hostPort 128.110.217.51:42171 with 16 core(s), 40.0 GiB RAM
21/11/09 04:23:29 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211109042329-0014/2 on worker-20211109002436-128.110.217.52-35535 (128.110.217.52:35535) with 16 core(s)
21/11/09 04:23:29 INFO StandaloneSchedulerBackend: Granted executor ID app-20211109042329-0014/2 on hostPort 128.110.217.52:35535 with 16 core(s), 40.0 GiB RAM
21/11/09 04:23:29 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41231.
21/11/09 04:23:29 INFO NettyBlockTransferService: Server created on ms0819.utah.cloudlab.us:41231
21/11/09 04:23:29 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/11/09 04:23:29 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, ms0819.utah.cloudlab.us, 41231, None)
21/11/09 04:23:29 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211109042329-0014/0 is now RUNNING
21/11/09 04:23:29 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211109042329-0014/2 is now RUNNING
21/11/09 04:23:29 INFO BlockManagerMasterEndpoint: Registering block manager ms0819.utah.cloudlab.us:41231 with 398.7 MiB RAM, BlockManagerId(driver, ms0819.utah.cloudlab.us, 41231, None)
21/11/09 04:23:29 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211109042329-0014/1 is now RUNNING
21/11/09 04:23:29 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, ms0819.utah.cloudlab.us, 41231, None)
21/11/09 04:23:29 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, ms0819.utah.cloudlab.us, 41231, None)
21/11/09 04:23:29 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
21/11/09 04:23:29 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
================= **** ========== Running wQFM on Spark ============== **** ====================
21/11/09 04:23:50 ERROR StandaloneSchedulerBackend: Application has been killed. Reason: Master removed our application: KILLED
21/11/09 04:23:50 ERROR TaskSchedulerImpl: Lost executor 1 on 128.110.217.51: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
21/11/09 04:23:50 WARN TaskSetManager: Lost task 23.0 in stage 0.0 (TID 23) (128.110.217.51 executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
21/11/09 04:23:50 WARN TaskSetManager: Lost task 8.0 in stage 0.0 (TID 8) (128.110.217.51 executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
21/11/09 04:23:50 WARN TaskSetManager: Lost task 26.0 in stage 0.0 (TID 26) (128.110.217.51 executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
21/11/09 04:23:50 WARN TaskSetManager: Lost task 11.0 in stage 0.0 (TID 11) (128.110.217.51 executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
21/11/09 04:23:50 WARN TaskSetManager: Lost task 2.0 in stage 0.0 (TID 2) (128.110.217.51 executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
21/11/09 04:23:50 WARN TaskSetManager: Lost task 5.0 in stage 0.0 (TID 5) (128.110.217.51 executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
21/11/09 04:23:50 WARN TaskSetManager: Lost task 14.0 in stage 0.0 (TID 14) (128.110.217.51 executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
21/11/09 04:23:50 ERROR TaskSchedulerImpl: Lost executor 2 on 128.110.217.52: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
21/11/09 04:23:50 WARN TaskSetManager: Lost task 27.0 in stage 0.0 (TID 27) (128.110.217.52 executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
21/11/09 04:23:50 WARN TaskSetManager: Lost task 9.0 in stage 0.0 (TID 9) (128.110.217.52 executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
21/11/09 04:23:50 WARN TaskSetManager: Lost task 18.0 in stage 0.0 (TID 18) (128.110.217.52 executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
21/11/09 04:23:50 WARN TaskSetManager: Lost task 12.0 in stage 0.0 (TID 12) (128.110.217.52 executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
21/11/09 04:23:50 WARN TaskSetManager: Lost task 3.0 in stage 0.0 (TID 3) (128.110.217.52 executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
21/11/09 04:23:50 WARN TaskSetManager: Lost task 21.0 in stage 0.0 (TID 21) (128.110.217.52 executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
21/11/09 04:23:50 WARN TaskSetManager: Lost task 30.0 in stage 0.0 (TID 30) (128.110.217.52 executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
21/11/09 04:23:50 WARN TaskSetManager: Lost task 15.0 in stage 0.0 (TID 15) (128.110.217.52 executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
21/11/09 04:23:50 WARN TaskSetManager: Lost task 6.0 in stage 0.0 (TID 6) (128.110.217.52 executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
21/11/09 04:23:50 WARN TaskSetManager: Lost task 24.0 in stage 0.0 (TID 24) (128.110.217.52 executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
21/11/09 04:23:50 WARN TaskSetManager: Lost task 0.0 in stage 0.0 (TID 0) (128.110.217.52 executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
21/11/09 04:23:50 ERROR TaskSchedulerImpl: Lost executor 0 on 128.110.217.44: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
21/11/09 04:23:50 WARN TaskSetManager: Lost task 40.0 in stage 0.0 (TID 40) (128.110.217.44 executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
21/11/09 04:23:50 WARN TaskSetManager: Lost task 4.0 in stage 0.0 (TID 4) (128.110.217.44 executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
21/11/09 04:23:50 WARN TaskSetManager: Lost task 13.0 in stage 0.0 (TID 13) (128.110.217.44 executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
21/11/09 04:23:50 WARN TaskSetManager: Lost task 22.0 in stage 0.0 (TID 22) (128.110.217.44 executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
21/11/09 04:23:50 WARN TaskSetManager: Lost task 7.0 in stage 0.0 (TID 7) (128.110.217.44 executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
21/11/09 04:23:50 WARN TaskSetManager: Lost task 16.0 in stage 0.0 (TID 16) (128.110.217.44 executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
21/11/09 04:23:50 WARN TaskSetManager: Lost task 25.0 in stage 0.0 (TID 25) (128.110.217.44 executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
21/11/09 04:23:50 WARN TaskSetManager: Lost task 10.0 in stage 0.0 (TID 10) (128.110.217.44 executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
21/11/09 04:23:50 WARN TaskSetManager: Lost task 1.0 in stage 0.0 (TID 1) (128.110.217.44 executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
21/11/09 04:23:50 WARN TaskSetManager: Lost task 19.0 in stage 0.0 (TID 19) (128.110.217.44 executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
Exception in thread "main" org.apache.spark.SparkException: Job 0 cancelled because SparkContext was shut down
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$cleanUpAfterSchedulerStop$1(DAGScheduler.scala:1085)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$cleanUpAfterSchedulerStop$1$adapted(DAGScheduler.scala:1083)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:79)
	at org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:1083)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:2463)
	at org.apache.spark.util.EventLoop.stop(EventLoop.scala:84)
	at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2369)
	at org.apache.spark.SparkContext.$anonfun$stop$12(SparkContext.scala:2069)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1419)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anon$3.run(SparkContext.scala:2018)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2291)
	at org.apache.spark.rdd.RDD.$anonfun$reduce$1(RDD.scala:1120)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:414)
	at org.apache.spark.rdd.RDD.reduce(RDD.scala:1102)
	at org.apache.spark.sql.Dataset.$anonfun$reduce$1(Dataset.scala:1746)
	at org.apache.spark.sql.Dataset.$anonfun$withNewRDDExecutionId$1(Dataset.scala:3676)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
	at org.apache.spark.sql.Dataset.withNewRDDExecutionId(Dataset.scala:3674)
	at org.apache.spark.sql.Dataset.reduce(Dataset.scala:1746)
	at org.apache.spark.sql.Dataset.reduce(Dataset.scala:1757)
	at algorithm.Distributer.initialiZeTaxaTable(Distributer.java:62)
	at algorithm.Distributer.runFunctions(Distributer.java:30)
	at main.App.runwQFMSpark(App.java:24)
	at main.App.initializeAndRun(App.java:45)
	at main.App.main(App.java:59)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:951)
	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180)
	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203)
	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1039)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1048)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
21/11/09 04:23:50 ERROR Utils: Uncaught exception in thread stop-spark-context
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.deploy.client.StandaloneAppClient.stop(StandaloneAppClient.scala:287)
	at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.org$apache$spark$scheduler$cluster$StandaloneSchedulerBackend$$stop(StandaloneSchedulerBackend.scala:259)
	at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.stop(StandaloneSchedulerBackend.scala:131)
	at org.apache.spark.scheduler.TaskSchedulerImpl.stop(TaskSchedulerImpl.scala:881)
	at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2370)
	at org.apache.spark.SparkContext.$anonfun$stop$12(SparkContext.scala:2069)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1419)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anon$3.run(SparkContext.scala:2018)
Caused by: org.apache.spark.SparkException: Could not find AppClient.
	at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:176)
	at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:144)
	at org.apache.spark.rpc.netty.NettyRpcEnv.askAbortable(NettyRpcEnv.scala:242)
	at org.apache.spark.rpc.netty.NettyRpcEndpointRef.askAbortable(NettyRpcEnv.scala:555)
	at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:559)
	at org.apache.spark.rpc.RpcEndpointRef.ask(RpcEndpointRef.scala:74)
	... 9 more
