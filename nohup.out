21/11/09 11:32:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/11/09 11:32:44 INFO SparkContext: Running Spark version 3.1.2
21/11/09 11:32:44 INFO ResourceUtils: ==============================================================
21/11/09 11:32:44 INFO ResourceUtils: No custom resources configured for spark.driver.
21/11/09 11:32:44 INFO ResourceUtils: ==============================================================
21/11/09 11:32:44 INFO SparkContext: Submitted application: wQFMSpark
21/11/09 11:32:44 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 40960, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/11/09 11:32:44 INFO ResourceProfile: Limiting resource is cpu
21/11/09 11:32:44 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/11/09 11:32:45 INFO SecurityManager: Changing view acls to: kab076
21/11/09 11:32:45 INFO SecurityManager: Changing modify acls to: kab076
21/11/09 11:32:45 INFO SecurityManager: Changing view acls groups to: 
21/11/09 11:32:45 INFO SecurityManager: Changing modify acls groups to: 
21/11/09 11:32:45 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(kab076); groups with view permissions: Set(); users  with modify permissions: Set(kab076); groups with modify permissions: Set()
21/11/09 11:32:45 INFO Utils: Successfully started service 'sparkDriver' on port 37227.
21/11/09 11:32:45 INFO SparkEnv: Registering MapOutputTracker
21/11/09 11:32:45 INFO SparkEnv: Registering BlockManagerMaster
21/11/09 11:32:45 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/11/09 11:32:45 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/11/09 11:32:45 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/11/09 11:32:45 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-f2b981ab-1902-4669-8154-20c26ad1771c
21/11/09 11:32:45 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/11/09 11:32:45 INFO SparkEnv: Registering OutputCommitCoordinator
21/11/09 11:32:45 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/11/09 11:32:45 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://ms0819.utah.cloudlab.us:4040
21/11/09 11:32:45 INFO SparkContext: Added JAR file:/users/kab076/wQFMSpark/./target/wQFMSpark-1.0-SNAPSHOT-jar-with-dependencies.jar at spark://ms0819.utah.cloudlab.us:37227/jars/wQFMSpark-1.0-SNAPSHOT-jar-with-dependencies.jar with timestamp 1636482764815
21/11/09 11:32:45 INFO SparkContext: Added file file:///users/kab076/wQFMSpark/triplets.soda2103 at spark://ms0819.utah.cloudlab.us:37227/files/triplets.soda2103 with timestamp 1636482764815
21/11/09 11:32:45 INFO Utils: Copying /users/kab076/wQFMSpark/triplets.soda2103 to /tmp/spark-c9ba962f-ade0-484f-9593-1d77bf264c94/userFiles-1b090ef0-6457-496f-bbf8-d65c31a39cad/triplets.soda2103
21/11/09 11:32:46 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://node0:7077...
21/11/09 11:32:46 INFO TransportClientFactory: Successfully created connection to node0/10.10.1.1:7077 after 44 ms (0 ms spent in bootstraps)
21/11/09 11:32:46 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211109113246-0030
21/11/09 11:32:46 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211109113246-0030/0 on worker-20211109002414-128.110.217.44-43329 (128.110.217.44:43329) with 16 core(s)
21/11/09 11:32:46 INFO StandaloneSchedulerBackend: Granted executor ID app-20211109113246-0030/0 on hostPort 128.110.217.44:43329 with 16 core(s), 40.0 GiB RAM
21/11/09 11:32:46 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211109113246-0030/1 on worker-20211109002452-128.110.217.51-42171 (128.110.217.51:42171) with 16 core(s)
21/11/09 11:32:46 INFO StandaloneSchedulerBackend: Granted executor ID app-20211109113246-0030/1 on hostPort 128.110.217.51:42171 with 16 core(s), 40.0 GiB RAM
21/11/09 11:32:46 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211109113246-0030/2 on worker-20211109002436-128.110.217.52-35535 (128.110.217.52:35535) with 16 core(s)
21/11/09 11:32:46 INFO StandaloneSchedulerBackend: Granted executor ID app-20211109113246-0030/2 on hostPort 128.110.217.52:35535 with 16 core(s), 40.0 GiB RAM
21/11/09 11:32:46 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43059.
21/11/09 11:32:46 INFO NettyBlockTransferService: Server created on ms0819.utah.cloudlab.us:43059
21/11/09 11:32:46 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/11/09 11:32:46 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211109113246-0030/0 is now RUNNING
21/11/09 11:32:46 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211109113246-0030/1 is now RUNNING
21/11/09 11:32:46 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211109113246-0030/2 is now RUNNING
21/11/09 11:32:46 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, ms0819.utah.cloudlab.us, 43059, None)
21/11/09 11:32:46 INFO BlockManagerMasterEndpoint: Registering block manager ms0819.utah.cloudlab.us:43059 with 398.7 MiB RAM, BlockManagerId(driver, ms0819.utah.cloudlab.us, 43059, None)
21/11/09 11:32:46 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, ms0819.utah.cloudlab.us, 43059, None)
21/11/09 11:32:46 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, ms0819.utah.cloudlab.us, 43059, None)
21/11/09 11:32:46 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
21/11/09 11:32:46 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
================= **** ========== Running wQFM on Spark ============== **** ====================
Final Taxa Table: TaxaTable{TAXA_COUNT=101,
 TAXA_LIST=[72, 97, 81, 90, 91, 92, 93, 94, 95, 96, 98, 99, 82, 83, 84, 85, 86, 87, 88, 89, 9, 73, 74, 75, 76, 77, 78, 79, 8, 80, 33, 61, 62, 34, 35, 36, 37, 38, 39, 4, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 5, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 6, 60, 63, 64, 65, 66, 67, 68, 69, 7, 70, 71, 23, 24, 25, 26, 27, 28, 29, 3, 30, 31, 32, 21, 22, 19, 2, 20, 15, 16, 17, 18, 13, 14, 10, 100, 11, 12, 1, 0],
 TAXA_PARTITION_LIST Size=132}
+---+-------+
|tag|count  |
+---+-------+
|125|18058  |
|124|77050  |
|112|36622  |
|64 |8227   |
|113|363833 |
|110|1986017|
|96 |1032   |
|126|243    |
|120|383982 |
|89 |3535817|
|118|79862  |
|90 |616160 |
|111|412896 |
|95 |43432  |
|93 |24     |
|115|178444 |
|92 |120    |
|122|29762  |
|117|106828 |
|114|621612 |
+---+-------+
only showing top 20 rows

+-----+-----+---+
|value|count|tag|
+-----+-----+---+
+-----+-----+---+

Number of Partitions by taxaPartition: 32
Printing Partition details
+-------+
|  value|
+-------+
|4891845|
|6395702|
| 929606|
+-------+

NumPartitions: 3
Number of Data Partitions: 3
Total generated trees: 3
+----------+------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|support   |tag                                             |tree                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |
+----------+------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|2.13815E9 |120|121|122|13|64|62|63|124|125|126|127|36|89|88|(((2,(15,(54,(29,26)))),(((7,(30,(36,23))),(((28,(4,13)),((66,(51,(21,43))),((18,65),(42,72)))),(((22,(27,61)),((60,38),(44,71,9))),((3,(67,8)),(64,(57,(63,19))))))),(((34,(68,(5,59))),(10,(50,(40,12)))),((20,((55,46),(70,(6,(32,(69,39)))))),((45,(14,35)),(48,(58,((41,49),(17,(31,25)))))))))),((0,((56,(1,16)),(24,(33,((53,47),(52,(11,(62,37)))))))),(86,(((81,76),(75,(73,77))),(((78,92),(96,99)),((80,(89,94)),(100,((84,(74,90)),((95,((97,91),(82,93))),((87,79),((88,83),(98,85))))))))))));|
|1.634478E9|119|118|117|116|114|113|115|110|112|111         |(((15,2,(54,(26,29))),((((10,(50,(40,12))),(34,(68,(59,5)))),(((45,(14,35)),(48,(58,((41,49),(17,(25,31)))))),(20,((46,55),(70,(6,(32,(69,39)))))))),((7,(23,36,30)),(((28,(4,13)),((66,(51,(43,21))),((18,65),(42,72)))),(((22,(61,27)),((60,38),(44,(9,71)))),((3,(8,67)),(64,(57,(63,19))))))))),((0,((56,(16,1)),(24,(33,((53,47),(52,(11,(62,37)))))))),(86,(((76,81),(75,(77,73))),(((78,92),(99,96)),(((94,89),(100,80)),((84,(90,74)),((95,((97,91),(82,93))),((79,87),((83,88),(98,85)))))))))));  |
|3.10297E8 |90|91|95|96|97|92|93                            |(((2,(15,(54,26,29))),((((50,(12,40)),(34,(68,(5,59)))),(((45,(14,35)),(48,(58,((41,49),(17,(25,31)))))),(20,((46,55),(70,(6,(32,(39,69)))))))),((7,(23,30,36)),(((28,(13,4)),((66,(43,21,51)),((18,65),(42,72)))),(((27,61,22),((38,60),(44,(71,9)))),((3,(8,67)),(64,(57,(63,19))))))))),(((16,56),(52,53,24,62,33,37,47)),(86,(((76,81),(75,(77,73))),(((96,99),(92,78)),((80,(94,89)),((84,(90,74)),((87,79),(82,83,85,88,91,93,95,97,98)))))))));                                                      |
+----------+------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

All Mapped Tasks Complete, Elapsed time: 1325362
Final tree (((2,(15,(54,(29,26)))),(((7,(30,(36,23))),(((28,(4,13)),((66,(51,(21,43))),((18,65),(42,72)))),(((22,(27,61)),((60,38),(44,71,9))),((3,(67,8)),(64,(57,(63,19))))))),(((34,(68,(5,59))),(10,(50,(40,12)))),((20,((55,46),(70,(6,(32,(69,39)))))),((45,(14,35)),(48,(58,((41,49),(17,(31,25)))))))))),((0,((56,(1,16)),(24,(33,((53,47),(52,(11,(62,37)))))))),(86,(((81,76),(75,(73,77))),(((78,92),(96,99)),((80,(89,94)),(100,((84,(74,90)),((95,((97,91),(82,93))),((87,79),((88,83),(98,85))))))))))));
distributedRunTree: (((2,(15,(54,(29,26)))),(((7,(30,(36,23))),(((28,(4,13)),((66,(51,(21,43))),((18,65),(42,72)))),(((22,(27,61)),((60,38),(44,71,9))),((3,(67,8)),(64,(57,(63,19))))))),(((34,(68,(5,59))),(10,(50,(40,12)))),((20,((55,46),(70,(6,(32,(69,39)))))),((45,(14,35)),(48,(58,((41,49),(17,(31,25)))))))))),((0,((56,(1,16)),(24,(33,((53,47),(52,(11,(62,37)))))))),(86,(((81,76),(75,(73,77))),(((78,92),(96,99)),((80,(89,94)),(100,((84,(74,90)),((95,((97,91),(82,93))),((87,79),((88,83),(98,85))))))))))));

Time taken = 1412676 ms ==> 23 minutes and 32 seconds.
================= **** ======================== **** ====================
21/11/09 12:26:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/11/09 12:26:28 INFO SparkContext: Running Spark version 3.1.2
21/11/09 12:26:29 INFO ResourceUtils: ==============================================================
21/11/09 12:26:29 INFO ResourceUtils: No custom resources configured for spark.driver.
21/11/09 12:26:29 INFO ResourceUtils: ==============================================================
21/11/09 12:26:29 INFO SparkContext: Submitted application: wQFMSpark
21/11/09 12:26:29 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 40960, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/11/09 12:26:29 INFO ResourceProfile: Limiting resource is cpu
21/11/09 12:26:29 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/11/09 12:26:29 INFO SecurityManager: Changing view acls to: kab076
21/11/09 12:26:29 INFO SecurityManager: Changing modify acls to: kab076
21/11/09 12:26:29 INFO SecurityManager: Changing view acls groups to: 
21/11/09 12:26:29 INFO SecurityManager: Changing modify acls groups to: 
21/11/09 12:26:29 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(kab076); groups with view permissions: Set(); users  with modify permissions: Set(kab076); groups with modify permissions: Set()
21/11/09 12:26:29 INFO Utils: Successfully started service 'sparkDriver' on port 35947.
21/11/09 12:26:29 INFO SparkEnv: Registering MapOutputTracker
21/11/09 12:26:29 INFO SparkEnv: Registering BlockManagerMaster
21/11/09 12:26:29 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/11/09 12:26:29 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/11/09 12:26:29 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/11/09 12:26:29 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-0c76a72a-d8a8-4d4c-909e-08827940fd80
21/11/09 12:26:29 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/11/09 12:26:29 INFO SparkEnv: Registering OutputCommitCoordinator
21/11/09 12:26:29 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/11/09 12:26:30 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://ms0819.utah.cloudlab.us:4040
21/11/09 12:26:30 INFO SparkContext: Added JAR file:/users/kab076/wQFMSpark/./target/wQFMSpark-1.0-SNAPSHOT-jar-with-dependencies.jar at spark://ms0819.utah.cloudlab.us:35947/jars/wQFMSpark-1.0-SNAPSHOT-jar-with-dependencies.jar with timestamp 1636485988967
21/11/09 12:26:30 INFO SparkContext: Added file file:///users/kab076/wQFMSpark/triplets.soda2103 at spark://ms0819.utah.cloudlab.us:35947/files/triplets.soda2103 with timestamp 1636485988967
21/11/09 12:26:30 INFO Utils: Copying /users/kab076/wQFMSpark/triplets.soda2103 to /tmp/spark-672c71af-bedb-4c66-afeb-df6072c2493b/userFiles-31795947-80c5-49a4-96b2-d7c547eaaed0/triplets.soda2103
21/11/09 12:26:30 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://node0:7077...
21/11/09 12:26:30 INFO TransportClientFactory: Successfully created connection to node0/10.10.1.1:7077 after 42 ms (0 ms spent in bootstraps)
21/11/09 12:26:30 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211109122630-0031
21/11/09 12:26:30 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211109122630-0031/0 on worker-20211109002414-128.110.217.44-43329 (128.110.217.44:43329) with 16 core(s)
21/11/09 12:26:30 INFO StandaloneSchedulerBackend: Granted executor ID app-20211109122630-0031/0 on hostPort 128.110.217.44:43329 with 16 core(s), 40.0 GiB RAM
21/11/09 12:26:30 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211109122630-0031/1 on worker-20211109002452-128.110.217.51-42171 (128.110.217.51:42171) with 16 core(s)
21/11/09 12:26:30 INFO StandaloneSchedulerBackend: Granted executor ID app-20211109122630-0031/1 on hostPort 128.110.217.51:42171 with 16 core(s), 40.0 GiB RAM
21/11/09 12:26:30 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211109122630-0031/2 on worker-20211109002436-128.110.217.52-35535 (128.110.217.52:35535) with 16 core(s)
21/11/09 12:26:30 INFO StandaloneSchedulerBackend: Granted executor ID app-20211109122630-0031/2 on hostPort 128.110.217.52:35535 with 16 core(s), 40.0 GiB RAM
21/11/09 12:26:30 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39437.
21/11/09 12:26:30 INFO NettyBlockTransferService: Server created on ms0819.utah.cloudlab.us:39437
21/11/09 12:26:30 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/11/09 12:26:30 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211109122630-0031/2 is now RUNNING
21/11/09 12:26:30 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211109122630-0031/1 is now RUNNING
21/11/09 12:26:30 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211109122630-0031/0 is now RUNNING
21/11/09 12:26:30 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, ms0819.utah.cloudlab.us, 39437, None)
21/11/09 12:26:30 INFO BlockManagerMasterEndpoint: Registering block manager ms0819.utah.cloudlab.us:39437 with 398.7 MiB RAM, BlockManagerId(driver, ms0819.utah.cloudlab.us, 39437, None)
21/11/09 12:26:30 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, ms0819.utah.cloudlab.us, 39437, None)
21/11/09 12:26:30 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, ms0819.utah.cloudlab.us, 39437, None)
21/11/09 12:26:30 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
21/11/09 12:26:30 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
================= **** ========== Running wQFM on Spark ============== **** ====================
Final Taxa Table: TaxaTable{TAXA_COUNT=101,
 TAXA_LIST=[72, 97, 81, 90, 91, 92, 93, 94, 95, 96, 98, 99, 82, 83, 84, 85, 86, 87, 88, 89, 9, 73, 74, 75, 76, 77, 78, 79, 8, 80, 61, 65, 66, 62, 63, 64, 67, 68, 69, 7, 70, 71, 48, 58, 59, 6, 60, 49, 5, 50, 51, 52, 53, 54, 55, 56, 57, 33, 34, 35, 36, 37, 38, 39, 4, 40, 41, 42, 43, 44, 45, 46, 47, 29, 3, 30, 31, 32, 26, 27, 28, 21, 22, 23, 24, 25, 17, 18, 19, 2, 20, 15, 16, 14, 11, 12, 13, 0, 1, 10, 100],
 TAXA_PARTITION_LIST Size=1141}
+----+------+
|tag |count |
+----+------+
|829 |41987 |
|691 |42    |
|853 |807   |
|800 |352091|
|451 |312   |
|666 |264   |
|870 |1993  |
|447 |165   |
|613 |37461 |
|1043|18642 |
|1104|14146 |
|647 |1227  |
|442 |327   |
|1008|30913 |
|448 |105   |
|234 |123   |
|232 |13    |
|851 |13801 |
|635 |1270  |
|483 |33    |
+----+------+
only showing top 20 rows

+-----+-----+---+
|value|count|tag|
+-----+-----+---+
+-----+-----+---+

Number of Partitions by taxaPartition: 417
Printing Partition details
+-------+
|  value|
+-------+
|4019737|
|4095259|
|4102157|
+-------+

NumPartitions: 3
Number of Data Partitions: 3
Total generated trees: 2
+----------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|support   |tag                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |tree                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
+----------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|1.370213E9|851|827|852|847|845|843|841|839|837|835|833|831|829|826|848|856|828|836|834|832|830|850|855|838|840|854|846|844|842|849|853|822|824|821|817|813|810|808|811|809|823|819|815|825|937|938|935|936|932|933|930|931|820|876|890|889|888|891|887|886|885|884|883|882|881|880|879|878|877|875|874|873|872|871|870|869|868|867|865|864|863|862|861|892|860|859|858|818|857|816|814|812|866                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |((((16,56),(24,(33,((53,47),(52,(11,(37,62))))))),(86,(((81,76),(75,(77,73))),(((78,92),(99,96)),(((94,89),(100,80)),((84,(74,90)),((95,((91,97),(93,82))),((79,87),((88,83),(85,98)))))))))),((2,(15,(54,(29,26)))),((((10,(50,(12,40))),(34,(68,(5,59)))),(((45,(14,35)),(48,(58,((49,41),(17,(31,25)))))),(20,((46,55),(70,(6,(32,(39,69)))))))),((7,(30,(36,23))),(((28,(13,4)),((66,(51,(43,21))),((65,18),(42,72)))),(((22,(27,61)),((38,60),(44,(71,9)))),((3,(8,67)),(64,(57,(19,63))))))))));        |
|1.347015E9|1139|1140|1138|1137|1136|1135|1132|1134|1133|1131|1130|1128|1129|1125|1127|1126|1121|1124|1123|1122|1117|1120|1119|1118|1113|1116|1115|1114|1109|1112|1111|1110|1105|1108|1107|1106|1101|1104|1103|1102|1100|1099|1098|1097|1096|1095|612|600|621|613|1048|616|615|1055|1051|1044|620|1043|1040|1037|619|1034|617|618|614|611|609|610|608|607|1054|1050|606|605|604|603|602|601|1042|1036|1033|1041|1038|1035|1045|1088|1083|1086|1085|1039|1092|1087|656|653|652|651|631|629|627|626|625|624|1065|628|1061|1053|1049|658|650|649|648|647|646|645|644|643|642|641|640|639|638|637|636|635|634|1081|623|1077|1073|1069|1057|654|661|633|1046|807|806|805|804|803|802|801|800|681|677|668|669|667|632|630|471|472|731|485|484|482|481|479|478|476|486|483|480|477|662|666|691|622|433|444|442|435|434|449|438|679|298|297|496|226|455|699|696|453|693|688|445|443|439|237|234|233|474|232|230|229|447|414|413|412|411|410|409|408|407|406|422|419|227|448|446|421|418|417|416|415|405|1084|258|660|236|1076|657|671|1075|1074|1066|1064|223|228|430|1063|207|1052|457|1047|1082|1062|655|425|427|426|458|424|459|454|452|450|436|432|431|428|665|206|429|423|451|440|441|456|694|292|293|494|493|491|490|488|487|1080|1079|1072|1071|1060|1059|1089|1068|1067|1056|697|690|1070|240|(((2,(15,(54,(26,29)))),((((10,(50,(40,12))),(34,(68,(59,5)))),(((45,(35,14)),(48,(58,((41,49),(17,(25,31)))))),(20,((46,55),(70,(6,(32,(39,69)))))))),((7,(30,(23,36))),(((28,(4,13)),((66,(51,(43,21))),((18,65),(42,72)))),(((22,(61,27)),((38,60),(44,(9,71)))),((3,(67,8)),(64,(57,(19,63))))))))),((0,((56,(1,16)),(24,(33,((53,47),(52,(11,(37,62)))))))),(86,(((81,76),(75,(73,77))),(((78,92),(96,99)),(((89,94),(80,100)),((84,(74,90)),((95,((97,91),(82,93))),((79,87),((88,83),(98,85)))))))))));|
+----------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

All Mapped Tasks Complete, Elapsed time: 1215749
Final tree (((2,(15,(54,(26,29)))),((((10,(50,(40,12))),(34,(68,(59,5)))),(((45,(35,14)),(48,(58,((41,49),(17,(25,31)))))),(20,((46,55),(70,(6,(32,(39,69)))))))),((7,(30,(23,36))),(((28,(4,13)),((66,(51,(43,21))),((18,65),(42,72)))),(((22,(61,27)),((38,60),(44,(9,71)))),((3,(67,8)),(64,(57,(19,63))))))))),((0,((56,(1,16)),(24,(33,((53,47),(52,(11,(37,62)))))))),(86,(((81,76),(75,(73,77))),(((78,92),(96,99)),(((89,94),(80,100)),((84,(74,90)),((95,((97,91),(82,93))),((79,87),((88,83),(98,85)))))))))));
distributedRunTree: (((2,(15,(54,(26,29)))),((((10,(50,(40,12))),(34,(68,(59,5)))),(((45,(35,14)),(48,(58,((41,49),(17,(25,31)))))),(20,((46,55),(70,(6,(32,(39,69)))))))),((7,(30,(23,36))),(((28,(4,13)),((66,(51,(43,21))),((18,65),(42,72)))),(((22,(61,27)),((38,60),(44,(9,71)))),((3,(67,8)),(64,(57,(19,63))))))))),((0,((56,(1,16)),(24,(33,((53,47),(52,(11,(37,62)))))))),(86,(((81,76),(75,(73,77))),(((78,92),(96,99)),(((89,94),(80,100)),((84,(74,90)),((95,((97,91),(82,93))),((79,87),((88,83),(98,85)))))))))));

Time taken = 1618976 ms ==> 26 minutes and 58 seconds.
================= **** ======================== **** ====================
21/11/09 13:00:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/11/09 13:00:16 INFO SparkContext: Running Spark version 3.1.2
21/11/09 13:00:16 INFO ResourceUtils: ==============================================================
21/11/09 13:00:16 INFO ResourceUtils: No custom resources configured for spark.driver.
21/11/09 13:00:16 INFO ResourceUtils: ==============================================================
21/11/09 13:00:16 INFO SparkContext: Submitted application: wQFMSpark
21/11/09 13:00:16 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 40960, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/11/09 13:00:16 INFO ResourceProfile: Limiting resource is cpu
21/11/09 13:00:16 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/11/09 13:00:16 INFO SecurityManager: Changing view acls to: kab076
21/11/09 13:00:16 INFO SecurityManager: Changing modify acls to: kab076
21/11/09 13:00:16 INFO SecurityManager: Changing view acls groups to: 
21/11/09 13:00:16 INFO SecurityManager: Changing modify acls groups to: 
21/11/09 13:00:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(kab076); groups with view permissions: Set(); users  with modify permissions: Set(kab076); groups with modify permissions: Set()
21/11/09 13:00:16 INFO Utils: Successfully started service 'sparkDriver' on port 42969.
21/11/09 13:00:16 INFO SparkEnv: Registering MapOutputTracker
21/11/09 13:00:16 INFO SparkEnv: Registering BlockManagerMaster
21/11/09 13:00:16 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/11/09 13:00:16 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/11/09 13:00:16 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/11/09 13:00:16 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-977894c0-6cc9-41dd-b4cd-bd3f3b8eaf83
21/11/09 13:00:16 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/11/09 13:00:16 INFO SparkEnv: Registering OutputCommitCoordinator
21/11/09 13:00:16 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/11/09 13:00:16 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://ms0819.utah.cloudlab.us:4040
21/11/09 13:00:16 INFO SparkContext: Added JAR file:/users/kab076/wQFMSpark/./target/wQFMSpark-1.0-SNAPSHOT-jar-with-dependencies.jar at spark://ms0819.utah.cloudlab.us:42969/jars/wQFMSpark-1.0-SNAPSHOT-jar-with-dependencies.jar with timestamp 1636488016141
21/11/09 13:00:16 INFO SparkContext: Added file file:///users/kab076/wQFMSpark/triplets.soda2103 at spark://ms0819.utah.cloudlab.us:42969/files/triplets.soda2103 with timestamp 1636488016141
21/11/09 13:00:16 INFO Utils: Copying /users/kab076/wQFMSpark/triplets.soda2103 to /tmp/spark-ae0f4908-54b4-499b-ac8e-569ede84a986/userFiles-54c3fee0-329c-4e7a-9291-6bb40e9dc901/triplets.soda2103
21/11/09 13:00:17 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://node0:7077...
21/11/09 13:00:17 INFO TransportClientFactory: Successfully created connection to node0/10.10.1.1:7077 after 61 ms (0 ms spent in bootstraps)
21/11/09 13:00:17 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211109130017-0032
21/11/09 13:00:17 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211109130017-0032/0 on worker-20211109002414-128.110.217.44-43329 (128.110.217.44:43329) with 16 core(s)
21/11/09 13:00:17 INFO StandaloneSchedulerBackend: Granted executor ID app-20211109130017-0032/0 on hostPort 128.110.217.44:43329 with 16 core(s), 40.0 GiB RAM
21/11/09 13:00:17 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211109130017-0032/1 on worker-20211109002452-128.110.217.51-42171 (128.110.217.51:42171) with 16 core(s)
21/11/09 13:00:17 INFO StandaloneSchedulerBackend: Granted executor ID app-20211109130017-0032/1 on hostPort 128.110.217.51:42171 with 16 core(s), 40.0 GiB RAM
21/11/09 13:00:17 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211109130017-0032/2 on worker-20211109002436-128.110.217.52-35535 (128.110.217.52:35535) with 16 core(s)
21/11/09 13:00:17 INFO StandaloneSchedulerBackend: Granted executor ID app-20211109130017-0032/2 on hostPort 128.110.217.52:35535 with 16 core(s), 40.0 GiB RAM
21/11/09 13:00:17 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41467.
21/11/09 13:00:17 INFO NettyBlockTransferService: Server created on ms0819.utah.cloudlab.us:41467
21/11/09 13:00:17 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/11/09 13:00:17 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, ms0819.utah.cloudlab.us, 41467, None)
21/11/09 13:00:17 INFO BlockManagerMasterEndpoint: Registering block manager ms0819.utah.cloudlab.us:41467 with 398.7 MiB RAM, BlockManagerId(driver, ms0819.utah.cloudlab.us, 41467, None)
21/11/09 13:00:17 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211109130017-0032/1 is now RUNNING
21/11/09 13:00:17 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211109130017-0032/0 is now RUNNING
21/11/09 13:00:17 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, ms0819.utah.cloudlab.us, 41467, None)
21/11/09 13:00:17 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211109130017-0032/2 is now RUNNING
21/11/09 13:00:17 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, ms0819.utah.cloudlab.us, 41467, None)
21/11/09 13:00:17 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
21/11/09 13:00:17 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
================= **** ========== Running wQFM on Spark ============== **** ====================
Final Taxa Table: TaxaTable{TAXA_COUNT=101,
 TAXA_LIST=[72, 97, 81, 90, 91, 92, 93, 94, 95, 96, 98, 99, 82, 83, 84, 85, 86, 87, 88, 89, 9, 73, 74, 75, 76, 77, 78, 79, 8, 80, 43, 65, 66, 44, 45, 46, 47, 48, 49, 5, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 6, 60, 61, 62, 63, 64, 67, 68, 69, 7, 70, 71, 41, 42, 3, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 4, 40, 29, 20, 21, 22, 23, 24, 25, 26, 27, 28, 18, 19, 2, 16, 17, 15, 14, 10, 12, 13, 100, 11, 0, 1],
 TAXA_PARTITION_LIST Size=1142}
+----+------+
|tag |count |
+----+------+
|691 |1339  |
|1090|1509  |
|675 |198   |
|467 |45    |
|829 |70763 |
|853 |5280  |
|800 |792608|
|666 |1092  |
|870 |760   |
|7   |90    |
|613 |54413 |
|1043|17826 |
|647 |741   |
|1104|78    |
|711 |309   |
|462 |1902  |
|470 |96    |
|442 |348   |
|1008|35143 |
|448 |60    |
+----+------+
only showing top 20 rows

+-----+-----+---+
|value|count|tag|
+-----+-----+---+
+-----+-----+---+

Number of Partitions by taxaPartition: 419
Printing Partition details
+-------+
|  value|
+-------+
|4164748|
|4153909|
|3898496|
+-------+

NumPartitions: 3
Number of Data Partitions: 3
21/11/09 13:18:20 WARN TaskSetManager: Lost task 2.0 in stage 26.0 (TID 750) (128.110.217.51 executor 1): org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.FSLimitException$PathComponentTooLongException): The maximum path component name limit of 969|947|955|953|951|949|970|948|915|914|916|910|909|907|906|904|903|901|900|899|898|897|896|895|894|893|875|876|874|872|873|868|867|866|865|864|863|862|861|860|857|859|858|855|856|853|854|851|852|849|850|847|848|845|846|843|844|841|842|839|840|837|838|836|835|834|833|823|824|826|821|825|822|819|820|817|818|815|816|813|814|811|812|809|810|807|808|805|806|803|804|802|827|832|831|829|828|830|889|887|888|885|884|883|881|882|879|878|877|869|870|932|892|886|880.wqrt in directory /user/kab076/exception is exceeded: limit=255 length=464
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyMaxComponentLength(FSDirectory.java:1186)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addLastINode(FSDirectory.java:1288)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addINode(FSDirectory.java:1113)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addFile(FSDirWriteFileOp.java:568)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:397)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2518)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2416)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:775)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:468)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy17.create(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:365)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy18.create(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:276)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1216)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1195)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1133)
	at org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:536)
	at org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:533)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:547)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:474)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)
	at util.HDFSWriter.writeToHDFS(HDFSWriter.java:21)
	at mapper.QuartetToTreeTablePartitionMapper.call(QuartetToTreeTablePartitionMapper.java:43)
	at org.apache.spark.sql.Dataset.$anonfun$mapPartitions$1(Dataset.scala:2820)
	at org.apache.spark.sql.execution.MapPartitionsExec.$anonfun$doExecute$3(objects.scala:195)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1423)
	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1350)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1414)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1237)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/11/09 13:31:37 WARN TaskSetManager: Lost task 2.1 in stage 26.0 (TID 751) (128.110.217.51 executor 1): org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.FSLimitException$PathComponentTooLongException): The maximum path component name limit of 969|947|955|953|951|949|970|948|915|914|916|910|909|907|906|904|903|901|900|899|898|897|896|895|894|893|875|876|874|872|873|868|867|866|865|864|863|862|861|860|857|859|858|855|856|853|854|851|852|849|850|847|848|845|846|843|844|841|842|839|840|837|838|836|835|834|833|823|824|826|821|825|822|819|820|817|818|815|816|813|814|811|812|809|810|807|808|805|806|803|804|802|827|832|831|829|828|830|889|887|888|885|884|883|881|882|879|878|877|869|870|932|892|886|880.wqrt in directory /user/kab076/exception is exceeded: limit=255 length=464
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyMaxComponentLength(FSDirectory.java:1186)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addLastINode(FSDirectory.java:1288)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addINode(FSDirectory.java:1113)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addFile(FSDirWriteFileOp.java:568)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:397)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2518)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2416)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:775)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:468)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy17.create(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:365)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy18.create(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:276)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1216)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1195)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1133)
	at org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:536)
	at org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:533)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:547)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:474)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)
	at util.HDFSWriter.writeToHDFS(HDFSWriter.java:21)
	at mapper.QuartetToTreeTablePartitionMapper.call(QuartetToTreeTablePartitionMapper.java:43)
	at org.apache.spark.sql.Dataset.$anonfun$mapPartitions$1(Dataset.scala:2820)
	at org.apache.spark.sql.execution.MapPartitionsExec.$anonfun$doExecute$3(objects.scala:195)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1423)
	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1350)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1414)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1237)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/11/09 13:41:59 WARN TaskSetManager: Lost task 2.2 in stage 26.0 (TID 752) (128.110.217.52 executor 2): org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.FSLimitException$PathComponentTooLongException): The maximum path component name limit of 955|953|969|951|949|947|895|898|970|932|915|910|907|904|901|897|894|914|909|906|903|900|916|893|899|896|856|857|853|854|851|852|850|847|848|845|846|844|841|842|839|840|837|838|836|835|875|876|872|873|866|867|863|864|860|861|859|858|855|843|834|874|868|865|862|849|833|823|829|821|819|817|815|813|811|809|807|805|803|830|824|820|818|816|814|812|810|808|806|804|802|892|832|889|887|888|882|883|881|877|870|869|831|826|828|825|827|948|822|885|884|879|878|886|880.wqrt in directory /user/kab076/exception is exceeded: limit=255 length=464
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyMaxComponentLength(FSDirectory.java:1186)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addLastINode(FSDirectory.java:1288)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addINode(FSDirectory.java:1113)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addFile(FSDirWriteFileOp.java:568)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:397)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2518)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2416)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:775)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:468)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy17.create(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:365)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy18.create(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:276)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1216)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1195)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1133)
	at org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:536)
	at org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:533)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:547)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:474)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)
	at util.HDFSWriter.writeToHDFS(HDFSWriter.java:21)
	at mapper.QuartetToTreeTablePartitionMapper.call(QuartetToTreeTablePartitionMapper.java:43)
	at org.apache.spark.sql.Dataset.$anonfun$mapPartitions$1(Dataset.scala:2820)
	at org.apache.spark.sql.execution.MapPartitionsExec.$anonfun$doExecute$3(objects.scala:195)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1423)
	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1350)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1414)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1237)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/11/09 13:55:30 WARN TaskSetManager: Lost task 2.3 in stage 26.0 (TID 753) (128.110.217.51 executor 1): org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.FSLimitException$PathComponentTooLongException): The maximum path component name limit of 969|947|955|953|951|949|970|948|915|914|916|910|909|907|906|904|903|901|900|899|898|897|896|895|894|893|875|876|874|872|873|868|867|866|865|864|863|862|861|860|857|859|858|855|856|853|854|851|852|849|850|847|848|845|846|843|844|841|842|839|840|837|838|836|835|834|833|823|824|826|821|825|822|819|820|817|818|815|816|813|814|811|812|809|810|807|808|805|806|803|804|802|827|832|831|829|828|830|889|887|888|885|884|883|881|882|879|878|877|869|870|932|892|886|880.wqrt in directory /user/kab076/exception is exceeded: limit=255 length=464
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyMaxComponentLength(FSDirectory.java:1186)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addLastINode(FSDirectory.java:1288)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addINode(FSDirectory.java:1113)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addFile(FSDirWriteFileOp.java:568)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:397)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2518)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2416)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:775)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:468)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy17.create(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:365)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy18.create(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:276)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1216)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1195)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1133)
	at org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:536)
	at org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:533)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:547)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:474)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)
	at util.HDFSWriter.writeToHDFS(HDFSWriter.java:21)
	at mapper.QuartetToTreeTablePartitionMapper.call(QuartetToTreeTablePartitionMapper.java:43)
	at org.apache.spark.sql.Dataset.$anonfun$mapPartitions$1(Dataset.scala:2820)
	at org.apache.spark.sql.execution.MapPartitionsExec.$anonfun$doExecute$3(objects.scala:195)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1423)
	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1350)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1414)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1237)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/11/09 13:55:30 ERROR TaskSetManager: Task 2 in stage 26.0 failed 4 times; aborting job
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 2 in stage 26.0 failed 4 times, most recent failure: Lost task 2.3 in stage 26.0 (TID 753) (128.110.217.51 executor 1): org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.FSLimitException$PathComponentTooLongException): The maximum path component name limit of 969|947|955|953|951|949|970|948|915|914|916|910|909|907|906|904|903|901|900|899|898|897|896|895|894|893|875|876|874|872|873|868|867|866|865|864|863|862|861|860|857|859|858|855|856|853|854|851|852|849|850|847|848|845|846|843|844|841|842|839|840|837|838|836|835|834|833|823|824|826|821|825|822|819|820|817|818|815|816|813|814|811|812|809|810|807|808|805|806|803|804|802|827|832|831|829|828|830|889|887|888|885|884|883|881|882|879|878|877|869|870|932|892|886|880.wqrt in directory /user/kab076/exception is exceeded: limit=255 length=464
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyMaxComponentLength(FSDirectory.java:1186)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addLastINode(FSDirectory.java:1288)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addINode(FSDirectory.java:1113)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addFile(FSDirWriteFileOp.java:568)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:397)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2518)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2416)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:775)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:468)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy17.create(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:365)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy18.create(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:276)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1216)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1195)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1133)
	at org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:536)
	at org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:533)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:547)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:474)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)
	at util.HDFSWriter.writeToHDFS(HDFSWriter.java:21)
	at mapper.QuartetToTreeTablePartitionMapper.call(QuartetToTreeTablePartitionMapper.java:43)
	at org.apache.spark.sql.Dataset.$anonfun$mapPartitions$1(Dataset.scala:2820)
	at org.apache.spark.sql.execution.MapPartitionsExec.$anonfun$doExecute$3(objects.scala:195)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1423)
	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1350)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1414)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1237)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1079)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1079)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1079)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2445)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2261)
	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:414)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:1029)
	at org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:390)
	at org.apache.spark.sql.Dataset.$anonfun$count$1(Dataset.scala:3006)
	at org.apache.spark.sql.Dataset.$anonfun$count$1$adapted(Dataset.scala:3005)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)
	at org.apache.spark.sql.Dataset.count(Dataset.scala:3005)
	at algorithm.Distributer.runExplained(Distributer.java:96)
	at algorithm.Distributer.partitionDataAndRun(Distributer.java:136)
	at algorithm.Distributer.runFunctions(Distributer.java:32)
	at main.App.runwQFMSpark(App.java:24)
	at main.App.initializeAndRun(App.java:45)
	at main.App.main(App.java:59)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:951)
	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180)
	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203)
	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1039)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1048)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.FSLimitException$PathComponentTooLongException): The maximum path component name limit of 969|947|955|953|951|949|970|948|915|914|916|910|909|907|906|904|903|901|900|899|898|897|896|895|894|893|875|876|874|872|873|868|867|866|865|864|863|862|861|860|857|859|858|855|856|853|854|851|852|849|850|847|848|845|846|843|844|841|842|839|840|837|838|836|835|834|833|823|824|826|821|825|822|819|820|817|818|815|816|813|814|811|812|809|810|807|808|805|806|803|804|802|827|832|831|829|828|830|889|887|888|885|884|883|881|882|879|878|877|869|870|932|892|886|880.wqrt in directory /user/kab076/exception is exceeded: limit=255 length=464
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyMaxComponentLength(FSDirectory.java:1186)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addLastINode(FSDirectory.java:1288)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addINode(FSDirectory.java:1113)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addFile(FSDirWriteFileOp.java:568)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:397)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2518)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2416)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:775)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:468)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy17.create(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:365)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy18.create(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:276)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1216)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1195)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1133)
	at org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:536)
	at org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:533)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:547)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:474)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)
	at util.HDFSWriter.writeToHDFS(HDFSWriter.java:21)
	at mapper.QuartetToTreeTablePartitionMapper.call(QuartetToTreeTablePartitionMapper.java:43)
	at org.apache.spark.sql.Dataset.$anonfun$mapPartitions$1(Dataset.scala:2820)
	at org.apache.spark.sql.execution.MapPartitionsExec.$anonfun$doExecute$3(objects.scala:195)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1423)
	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1350)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1414)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1237)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/11/09 23:58:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/11/09 23:58:46 INFO SparkContext: Running Spark version 3.1.2
21/11/09 23:58:46 INFO ResourceUtils: ==============================================================
21/11/09 23:58:46 INFO ResourceUtils: No custom resources configured for spark.driver.
21/11/09 23:58:46 INFO ResourceUtils: ==============================================================
21/11/09 23:58:46 INFO SparkContext: Submitted application: wQFMSpark
21/11/09 23:58:46 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 40960, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/11/09 23:58:46 INFO ResourceProfile: Limiting resource is cpu
21/11/09 23:58:46 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/11/09 23:58:46 INFO SecurityManager: Changing view acls to: kab076
21/11/09 23:58:46 INFO SecurityManager: Changing modify acls to: kab076
21/11/09 23:58:46 INFO SecurityManager: Changing view acls groups to: 
21/11/09 23:58:46 INFO SecurityManager: Changing modify acls groups to: 
21/11/09 23:58:46 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(kab076); groups with view permissions: Set(); users  with modify permissions: Set(kab076); groups with modify permissions: Set()
21/11/09 23:58:46 INFO Utils: Successfully started service 'sparkDriver' on port 33007.
21/11/09 23:58:46 INFO SparkEnv: Registering MapOutputTracker
21/11/09 23:58:46 INFO SparkEnv: Registering BlockManagerMaster
21/11/09 23:58:46 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/11/09 23:58:46 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/11/09 23:58:46 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/11/09 23:58:46 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-08de5f8a-a286-430b-a255-f5e6aeffee17
21/11/09 23:58:46 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/11/09 23:58:46 INFO SparkEnv: Registering OutputCommitCoordinator
21/11/09 23:58:46 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/11/09 23:58:46 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://ms0819.utah.cloudlab.us:4040
21/11/09 23:58:46 INFO SparkContext: Added JAR file:/users/kab076/wQFMSpark/./target/wQFMSpark-1.0-SNAPSHOT-jar-with-dependencies.jar at spark://ms0819.utah.cloudlab.us:33007/jars/wQFMSpark-1.0-SNAPSHOT-jar-with-dependencies.jar with timestamp 1636527526047
21/11/09 23:58:46 INFO SparkContext: Added file file:///users/kab076/wQFMSpark/triplets.soda2103 at spark://ms0819.utah.cloudlab.us:33007/files/triplets.soda2103 with timestamp 1636527526047
21/11/09 23:58:46 INFO Utils: Copying /users/kab076/wQFMSpark/triplets.soda2103 to /tmp/spark-d1e18dcb-481b-4dd3-a2a9-dae6d37985cf/userFiles-b43371aa-d42d-43b0-8960-5127475c7ce5/triplets.soda2103
21/11/09 23:58:47 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://node0:7077...
21/11/09 23:58:47 INFO TransportClientFactory: Successfully created connection to node0/10.10.1.1:7077 after 39 ms (0 ms spent in bootstraps)
21/11/09 23:58:47 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211109235847-0033
21/11/09 23:58:47 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211109235847-0033/0 on worker-20211109002414-128.110.217.44-43329 (128.110.217.44:43329) with 16 core(s)
21/11/09 23:58:47 INFO StandaloneSchedulerBackend: Granted executor ID app-20211109235847-0033/0 on hostPort 128.110.217.44:43329 with 16 core(s), 40.0 GiB RAM
21/11/09 23:58:47 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211109235847-0033/1 on worker-20211109002452-128.110.217.51-42171 (128.110.217.51:42171) with 16 core(s)
21/11/09 23:58:47 INFO StandaloneSchedulerBackend: Granted executor ID app-20211109235847-0033/1 on hostPort 128.110.217.51:42171 with 16 core(s), 40.0 GiB RAM
21/11/09 23:58:47 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211109235847-0033/2 on worker-20211109002436-128.110.217.52-35535 (128.110.217.52:35535) with 16 core(s)
21/11/09 23:58:47 INFO StandaloneSchedulerBackend: Granted executor ID app-20211109235847-0033/2 on hostPort 128.110.217.52:35535 with 16 core(s), 40.0 GiB RAM
21/11/09 23:58:47 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38841.
21/11/09 23:58:47 INFO NettyBlockTransferService: Server created on ms0819.utah.cloudlab.us:38841
21/11/09 23:58:47 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/11/09 23:58:47 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, ms0819.utah.cloudlab.us, 38841, None)
21/11/09 23:58:47 INFO BlockManagerMasterEndpoint: Registering block manager ms0819.utah.cloudlab.us:38841 with 398.7 MiB RAM, BlockManagerId(driver, ms0819.utah.cloudlab.us, 38841, None)
21/11/09 23:58:47 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, ms0819.utah.cloudlab.us, 38841, None)
21/11/09 23:58:47 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, ms0819.utah.cloudlab.us, 38841, None)
21/11/09 23:58:47 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211109235847-0033/1 is now RUNNING
21/11/09 23:58:47 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211109235847-0033/2 is now RUNNING
21/11/09 23:58:47 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211109235847-0033/0 is now RUNNING
21/11/09 23:58:47 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
21/11/09 23:58:47 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
================= **** ========== Running wQFM on Spark ============== **** ====================
Final Taxa Table: TaxaTable{TAXA_COUNT=101,
 TAXA_LIST=[72, 97, 81, 90, 91, 92, 93, 94, 95, 96, 98, 99, 82, 83, 84, 85, 86, 87, 88, 89, 9, 73, 74, 75, 76, 77, 78, 79, 8, 80, 61, 65, 66, 62, 63, 64, 67, 68, 69, 7, 70, 71, 51, 52, 53, 54, 55, 56, 57, 58, 59, 6, 60, 43, 44, 45, 46, 47, 48, 49, 5, 50, 41, 42, 36, 4, 40, 37, 38, 39, 32, 34, 35, 33, 29, 3, 30, 31, 26, 27, 28, 25, 21, 22, 23, 24, 20, 17, 18, 19, 2, 15, 16, 11, 12, 13, 14, 1, 10, 100, 0],
 TAXA_PARTITION_LIST Size=1142}
+----+------+
|tag |count |
+----+------+
|829 |16666 |
|675 |210   |
|691 |138   |
|1090|9     |
|853 |113247|
|800 |152825|
|451 |36    |
|870 |17915 |
|666 |317   |
|613 |71394 |
|1043|7038  |
|205 |939   |
|647 |684   |
|442 |1294  |
|448 |342   |
|1008|18541 |
|886 |6495  |
|862 |6394  |
|851 |612   |
|635 |1116  |
+----+------+
only showing top 20 rows

+-----+-----+---+
|value|count|tag|
+-----+-----+---+
+-----+-----+---+

Number of Partitions by taxaPartition: 361
Number of Data Partitions: 3
21/11/10 00:08:30 WARN TaskSetManager: Lost task 1.0 in stage 17.0 (TID 552) (128.110.217.52 executor 2): org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.FSLimitException$PathComponentTooLongException): The maximum path component name limit of 400|803|811|809|807|805|802|804|812|810|808|806|422|421|420|419|406|412|411|409|408|405|402|800|602|601|600|604|801|603|427|425|428|426|423|418|456|650|616|649|654|646|652|644|643|641|640|639|638|637|636|635|634|633|632|631|630|628|629|627|625|626|624|622|623|621|619|620|618|617|615|614|613|611|610|609|608|607|606|605|434|675|674|673|672|671|670|669|668|432|689|648|647|645|642|417|687|684|683|651|680|686|444|442|440|438|436|667|666|665|663|664|690|662|661|660|659|658|657|656|415|450|448|446|698|696|693|692|691|476|473|416|678|677|676|480|460|471|679|612|407|401|414|403|451|431|429|430|437|435|433|653|655|443|441|439.wqrt in directory /user/kab076/exception is exceeded: limit=255 length=628
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyMaxComponentLength(FSDirectory.java:1186)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addLastINode(FSDirectory.java:1288)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addINode(FSDirectory.java:1113)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addFile(FSDirWriteFileOp.java:568)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:397)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2518)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2416)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:775)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:468)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy17.create(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:365)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy18.create(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:276)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1216)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1195)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1133)
	at org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:536)
	at org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:533)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:547)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:474)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)
	at util.HDFSWriter.writeToHDFS(HDFSWriter.java:21)
	at mapper.QuartetToTreeTablePartitionMapper.call(QuartetToTreeTablePartitionMapper.java:43)
	at org.apache.spark.sql.Dataset.$anonfun$mapPartitions$1(Dataset.scala:2820)
	at org.apache.spark.sql.execution.MapPartitionsExec.$anonfun$doExecute$3(objects.scala:195)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1423)
	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1350)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1414)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1237)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/11/10 00:13:05 ERROR StandaloneSchedulerBackend: Application has been killed. Reason: Master removed our application: KILLED
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Master removed our application: KILLED
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1079)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1079)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1079)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2445)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2261)
	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:414)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:1029)
	at org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:390)
	at org.apache.spark.sql.Dataset.$anonfun$count$1(Dataset.scala:3006)
	at org.apache.spark.sql.Dataset.$anonfun$count$1$adapted(Dataset.scala:3005)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)
	at org.apache.spark.sql.Dataset.count(Dataset.scala:3005)
	at algorithm.Distributer.runExplained(Distributer.java:96)
	at algorithm.Distributer.partitionDataAndRun(Distributer.java:136)
	at algorithm.Distributer.runFunctions(Distributer.java:32)
	at main.App.runwQFMSpark(App.java:24)
	at main.App.initializeAndRun(App.java:45)
	at main.App.main(App.java:59)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:951)
	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180)
	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203)
	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1039)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1048)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
21/11/10 00:13:05 ERROR Utils: Uncaught exception in thread stop-spark-context
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.deploy.client.StandaloneAppClient.stop(StandaloneAppClient.scala:287)
	at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.org$apache$spark$scheduler$cluster$StandaloneSchedulerBackend$$stop(StandaloneSchedulerBackend.scala:259)
	at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.stop(StandaloneSchedulerBackend.scala:131)
	at org.apache.spark.scheduler.TaskSchedulerImpl.stop(TaskSchedulerImpl.scala:881)
	at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2370)
	at org.apache.spark.SparkContext.$anonfun$stop$12(SparkContext.scala:2069)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1419)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anon$3.run(SparkContext.scala:2018)
Caused by: org.apache.spark.SparkException: Could not find AppClient.
	at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:176)
	at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:144)
	at org.apache.spark.rpc.netty.NettyRpcEnv.askAbortable(NettyRpcEnv.scala:242)
	at org.apache.spark.rpc.netty.NettyRpcEndpointRef.askAbortable(NettyRpcEnv.scala:555)
	at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:559)
	at org.apache.spark.rpc.RpcEndpointRef.ask(RpcEndpointRef.scala:74)
	... 9 more
21/11/10 00:14:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/11/10 00:14:47 INFO SparkContext: Running Spark version 3.1.2
21/11/10 00:14:47 INFO ResourceUtils: ==============================================================
21/11/10 00:14:47 INFO ResourceUtils: No custom resources configured for spark.driver.
21/11/10 00:14:47 INFO ResourceUtils: ==============================================================
21/11/10 00:14:47 INFO SparkContext: Submitted application: wQFMSpark
21/11/10 00:14:47 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 40960, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/11/10 00:14:47 INFO ResourceProfile: Limiting resource is cpu
21/11/10 00:14:47 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/11/10 00:14:47 INFO SecurityManager: Changing view acls to: kab076
21/11/10 00:14:47 INFO SecurityManager: Changing modify acls to: kab076
21/11/10 00:14:47 INFO SecurityManager: Changing view acls groups to: 
21/11/10 00:14:47 INFO SecurityManager: Changing modify acls groups to: 
21/11/10 00:14:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(kab076); groups with view permissions: Set(); users  with modify permissions: Set(kab076); groups with modify permissions: Set()
21/11/10 00:14:47 INFO Utils: Successfully started service 'sparkDriver' on port 40283.
21/11/10 00:14:47 INFO SparkEnv: Registering MapOutputTracker
21/11/10 00:14:47 INFO SparkEnv: Registering BlockManagerMaster
21/11/10 00:14:47 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/11/10 00:14:47 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/11/10 00:14:47 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/11/10 00:14:47 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-45071565-b4c1-4925-a386-7b44a240b000
21/11/10 00:14:47 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/11/10 00:14:47 INFO SparkEnv: Registering OutputCommitCoordinator
21/11/10 00:14:48 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/11/10 00:14:48 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://ms0819.utah.cloudlab.us:4040
21/11/10 00:14:48 INFO SparkContext: Added JAR file:/users/kab076/wQFMSpark/./target/wQFMSpark-1.0-SNAPSHOT-jar-with-dependencies.jar at spark://ms0819.utah.cloudlab.us:40283/jars/wQFMSpark-1.0-SNAPSHOT-jar-with-dependencies.jar with timestamp 1636528487421
21/11/10 00:14:48 INFO SparkContext: Added file file:///users/kab076/wQFMSpark/triplets.soda2103 at spark://ms0819.utah.cloudlab.us:40283/files/triplets.soda2103 with timestamp 1636528487421
21/11/10 00:14:48 INFO Utils: Copying /users/kab076/wQFMSpark/triplets.soda2103 to /tmp/spark-efbdcc25-4466-489a-a351-ebde02ca6f57/userFiles-28234a5f-01e3-4680-abbd-eedd1dbfb6ff/triplets.soda2103
21/11/10 00:14:48 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://node0:7077...
21/11/10 00:14:48 INFO TransportClientFactory: Successfully created connection to node0/10.10.1.1:7077 after 46 ms (0 ms spent in bootstraps)
21/11/10 00:14:48 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211110001448-0034
21/11/10 00:14:48 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211110001448-0034/0 on worker-20211109002414-128.110.217.44-43329 (128.110.217.44:43329) with 16 core(s)
21/11/10 00:14:48 INFO StandaloneSchedulerBackend: Granted executor ID app-20211110001448-0034/0 on hostPort 128.110.217.44:43329 with 16 core(s), 40.0 GiB RAM
21/11/10 00:14:48 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211110001448-0034/1 on worker-20211109002452-128.110.217.51-42171 (128.110.217.51:42171) with 16 core(s)
21/11/10 00:14:48 INFO StandaloneSchedulerBackend: Granted executor ID app-20211110001448-0034/1 on hostPort 128.110.217.51:42171 with 16 core(s), 40.0 GiB RAM
21/11/10 00:14:48 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211110001448-0034/2 on worker-20211109002436-128.110.217.52-35535 (128.110.217.52:35535) with 16 core(s)
21/11/10 00:14:48 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34693.
21/11/10 00:14:48 INFO NettyBlockTransferService: Server created on ms0819.utah.cloudlab.us:34693
21/11/10 00:14:48 INFO StandaloneSchedulerBackend: Granted executor ID app-20211110001448-0034/2 on hostPort 128.110.217.52:35535 with 16 core(s), 40.0 GiB RAM
21/11/10 00:14:48 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/11/10 00:14:48 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, ms0819.utah.cloudlab.us, 34693, None)
21/11/10 00:14:48 INFO BlockManagerMasterEndpoint: Registering block manager ms0819.utah.cloudlab.us:34693 with 398.7 MiB RAM, BlockManagerId(driver, ms0819.utah.cloudlab.us, 34693, None)
21/11/10 00:14:48 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211110001448-0034/0 is now RUNNING
21/11/10 00:14:48 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, ms0819.utah.cloudlab.us, 34693, None)
21/11/10 00:14:48 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211110001448-0034/2 is now RUNNING
21/11/10 00:14:48 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, ms0819.utah.cloudlab.us, 34693, None)
21/11/10 00:14:48 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211110001448-0034/1 is now RUNNING
21/11/10 00:14:49 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
21/11/10 00:14:49 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
================= **** ========== Running wQFM on Spark ============== **** ====================
Final Taxa Table: TaxaTable{TAXA_COUNT=101,
 TAXA_LIST=[72, 97, 81, 90, 91, 92, 93, 94, 95, 96, 98, 99, 82, 83, 84, 85, 86, 87, 88, 89, 9, 73, 74, 75, 76, 77, 78, 79, 8, 80, 26, 61, 62, 63, 64, 65, 66, 67, 68, 69, 7, 70, 71, 27, 28, 29, 3, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 4, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 5, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 6, 60, 23, 24, 25, 15, 16, 17, 18, 19, 2, 20, 21, 22, 13, 14, 10, 100, 11, 12, 1, 0],
 TAXA_PARTITION_LIST Size=313}
+---+-------+
|tag|count  |
+---+-------+
|125|36197  |
|124|6225   |
|205|15     |
|169|660    |
|272|6588   |
|282|2060   |
|234|1294012|
|232|88048  |
|15 |23902  |
|132|300    |
|200|15     |
|279|45     |
|29 |4809   |
|42 |1323   |
|112|1368630|
|113|614742 |
|34 |23042  |
|287|6      |
|250|32847  |
|146|4386   |
+---+-------+
only showing top 20 rows

+-----+-----+---+
|value|count|tag|
+-----+-----+---+
+-----+-----+---+

Number of Partitions by taxaPartition: 139
Number of Data Partitions: 3
Total generated trees: 1
+----------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|support   |tag                                                                                                                                                                                                    |tree                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
+----------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|1.060754E9|254|240|239|255|241|252|253|251|250|249|248|247|246|245|244|243|242|256|238|237|275|271|276|33|34|269|289|288|287|279|286|285|284|283|282|58|270|236|235|29|267|257|268|280|274|281|292|291|272|290|293|(((2,(15,(54,(26,29)))),((((10,(50,(40,12))),(34,(68,(59,5)))),(((45,(14,35)),(48,(58,((41,49),(17,(31,25)))))),(20,((55,46),(70,(6,(32,(69,39)))))))),((7,(30,(36,23))),(((28,(13,4)),((66,(51,(43,21))),((65,18),(42,72)))),(((22,(27,61)),((60,38),(44,(9,71)))),((3,(67,8)),(64,(57,(19,63))))))))),(0,(((56,(16,1)),(24,(33,((53,47),(52,(11,(37,62))))))),(86,(((81,76),(75,(77,73))),(((78,92),(96,99)),(((89,94),(100,80)),((84,(74,90)),((95,((97,91),(82,93))),((79,87),((83,88),(98,85))))))))))));|
+----------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

All Mapped Tasks Complete, Elapsed time: 834360
Final tree (((2,(15,(54,(26,29)))),((((10,(50,(40,12))),(34,(68,(59,5)))),(((45,(14,35)),(48,(58,((41,49),(17,(31,25)))))),(20,((55,46),(70,(6,(32,(69,39)))))))),((7,(30,(36,23))),(((28,(13,4)),((66,(51,(43,21))),((65,18),(42,72)))),(((22,(27,61)),((60,38),(44,(9,71)))),((3,(67,8)),(64,(57,(19,63))))))))),(0,(((56,(16,1)),(24,(33,((53,47),(52,(11,(37,62))))))),(86,(((81,76),(75,(77,73))),(((78,92),(96,99)),(((89,94),(100,80)),((84,(74,90)),((95,((97,91),(82,93))),((79,87),((83,88),(98,85))))))))))));
distributedRunTree: (((2,(15,(54,(26,29)))),((((10,(50,(40,12))),(34,(68,(59,5)))),(((45,(14,35)),(48,(58,((41,49),(17,(31,25)))))),(20,((55,46),(70,(6,(32,(69,39)))))))),((7,(30,(36,23))),(((28,(13,4)),((66,(51,(43,21))),((65,18),(42,72)))),(((22,(27,61)),((60,38),(44,(9,71)))),((3,(67,8)),(64,(57,(19,63))))))))),(0,(((56,(16,1)),(24,(33,((53,47),(52,(11,(37,62))))))),(86,(((81,76),(75,(77,73))),(((78,92),(96,99)),(((89,94),(100,80)),((84,(74,90)),((95,((97,91),(82,93))),((79,87),((83,88),(98,85))))))))))));

Time taken = 911197 ms ==> 15 minutes and 11 seconds.
================= **** ======================== **** ====================
21/11/10 00:41:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/11/10 00:41:31 INFO SparkContext: Running Spark version 3.1.2
21/11/10 00:41:31 INFO ResourceUtils: ==============================================================
21/11/10 00:41:31 INFO ResourceUtils: No custom resources configured for spark.driver.
21/11/10 00:41:31 INFO ResourceUtils: ==============================================================
21/11/10 00:41:31 INFO SparkContext: Submitted application: wQFMSpark
21/11/10 00:41:31 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 40960, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/11/10 00:41:31 INFO ResourceProfile: Limiting resource is cpu
21/11/10 00:41:31 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/11/10 00:41:31 INFO SecurityManager: Changing view acls to: kab076
21/11/10 00:41:31 INFO SecurityManager: Changing modify acls to: kab076
21/11/10 00:41:31 INFO SecurityManager: Changing view acls groups to: 
21/11/10 00:41:31 INFO SecurityManager: Changing modify acls groups to: 
21/11/10 00:41:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(kab076); groups with view permissions: Set(); users  with modify permissions: Set(kab076); groups with modify permissions: Set()
21/11/10 00:41:31 INFO Utils: Successfully started service 'sparkDriver' on port 38333.
21/11/10 00:41:31 INFO SparkEnv: Registering MapOutputTracker
21/11/10 00:41:31 INFO SparkEnv: Registering BlockManagerMaster
21/11/10 00:41:31 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/11/10 00:41:31 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/11/10 00:41:31 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/11/10 00:41:31 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-fac8c5dd-5c9e-4fad-bf3d-11667b012073
21/11/10 00:41:31 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/11/10 00:41:31 INFO SparkEnv: Registering OutputCommitCoordinator
21/11/10 00:41:32 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/11/10 00:41:32 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://ms0819.utah.cloudlab.us:4040
21/11/10 00:41:32 INFO SparkContext: Added JAR file:/users/kab076/wQFMSpark/./target/wQFMSpark-1.0-SNAPSHOT-jar-with-dependencies.jar at spark://ms0819.utah.cloudlab.us:38333/jars/wQFMSpark-1.0-SNAPSHOT-jar-with-dependencies.jar with timestamp 1636530091036
21/11/10 00:41:32 INFO SparkContext: Added file file:///users/kab076/wQFMSpark/triplets.soda2103 at spark://ms0819.utah.cloudlab.us:38333/files/triplets.soda2103 with timestamp 1636530091036
21/11/10 00:41:32 INFO Utils: Copying /users/kab076/wQFMSpark/triplets.soda2103 to /tmp/spark-8b016363-4ff9-40ca-b499-8313450cba6e/userFiles-a402717a-7261-4c03-b086-1c8281b5b2aa/triplets.soda2103
21/11/10 00:41:32 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://node0:7077...
21/11/10 00:41:32 INFO TransportClientFactory: Successfully created connection to node0/10.10.1.1:7077 after 44 ms (0 ms spent in bootstraps)
21/11/10 00:41:32 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211110004132-0035
21/11/10 00:41:32 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211110004132-0035/0 on worker-20211109002414-128.110.217.44-43329 (128.110.217.44:43329) with 16 core(s)
21/11/10 00:41:32 INFO StandaloneSchedulerBackend: Granted executor ID app-20211110004132-0035/0 on hostPort 128.110.217.44:43329 with 16 core(s), 40.0 GiB RAM
21/11/10 00:41:32 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211110004132-0035/1 on worker-20211109002452-128.110.217.51-42171 (128.110.217.51:42171) with 16 core(s)
21/11/10 00:41:32 INFO StandaloneSchedulerBackend: Granted executor ID app-20211110004132-0035/1 on hostPort 128.110.217.51:42171 with 16 core(s), 40.0 GiB RAM
21/11/10 00:41:32 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211110004132-0035/2 on worker-20211109002436-128.110.217.52-35535 (128.110.217.52:35535) with 16 core(s)
21/11/10 00:41:32 INFO StandaloneSchedulerBackend: Granted executor ID app-20211110004132-0035/2 on hostPort 128.110.217.52:35535 with 16 core(s), 40.0 GiB RAM
21/11/10 00:41:32 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38743.
21/11/10 00:41:32 INFO NettyBlockTransferService: Server created on ms0819.utah.cloudlab.us:38743
21/11/10 00:41:32 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/11/10 00:41:32 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211110004132-0035/0 is now RUNNING
21/11/10 00:41:32 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211110004132-0035/1 is now RUNNING
21/11/10 00:41:32 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211110004132-0035/2 is now RUNNING
21/11/10 00:41:32 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, ms0819.utah.cloudlab.us, 38743, None)
21/11/10 00:41:32 INFO BlockManagerMasterEndpoint: Registering block manager ms0819.utah.cloudlab.us:38743 with 398.7 MiB RAM, BlockManagerId(driver, ms0819.utah.cloudlab.us, 38743, None)
21/11/10 00:41:32 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, ms0819.utah.cloudlab.us, 38743, None)
21/11/10 00:41:32 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, ms0819.utah.cloudlab.us, 38743, None)
21/11/10 00:41:32 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
21/11/10 00:41:32 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
================= **** ========== Running wQFM on Spark ============== **** ====================
Final Taxa Table: TaxaTable{TAXA_COUNT=101,
 TAXA_LIST=[72, 97, 81, 90, 91, 92, 93, 94, 95, 96, 98, 99, 82, 83, 84, 85, 86, 87, 88, 89, 9, 73, 74, 75, 76, 77, 78, 79, 8, 80, 33, 61, 62, 34, 35, 36, 37, 38, 39, 4, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 5, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 6, 60, 63, 64, 65, 66, 67, 68, 69, 7, 70, 71, 32, 26, 27, 28, 29, 3, 30, 31, 23, 24, 25, 18, 19, 20, 21, 22, 2, 16, 17, 12, 13, 14, 15, 100, 11, 10, 1, 0],
 TAXA_PARTITION_LIST Size=319}
+---+------+
|tag|count |
+---+------+
|125|8181  |
|124|11752 |
|7  |5293  |
|169|126   |
|272|1242  |
|234|108664|
|232|392286|
|155|5358  |
|132|864   |
|200|108   |
|11 |4968  |
|279|1248  |
|112|847286|
|113|566302|
|133|1620  |
|287|2484  |
|162|2376  |
|59 |15    |
|250|4233  |
|146|3378  |
+---+------+
only showing top 20 rows

+-----+-----+---+
|value|count|tag|
+-----+-----+---+
+-----+-----+---+

Number of Partitions by taxaPartition: 139
Number of Data Partitions: 3
Partitioning Tasks to workers ...
21/11/10 00:55:07 WARN TaskSetManager: Lost task 1.0 in stage 19.0 (TID 565) (128.110.217.44 executor 0): org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.FSLimitException$PathComponentTooLongException): The maximum path component name limit of 230|188|180|185|189|184|183|182|181|158|177|178|163|162|161|160|159|143|166|176|179|156|155|150|144|149|128|129|130|127|126|125|124|131|135|134|136|133|132|119|123|122|121|115|116|114|117|140|118|193|191|200|199|198|197|196|190|148|147|146|151|169|165|120|141.wqrt in directory /user/kab076/exception is exceeded: limit=255 length=264
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyMaxComponentLength(FSDirectory.java:1186)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addLastINode(FSDirectory.java:1288)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addINode(FSDirectory.java:1113)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addFile(FSDirWriteFileOp.java:568)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:397)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2518)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2416)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:775)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:468)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy17.create(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:365)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy18.create(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:276)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1216)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1195)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1133)
	at org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:536)
	at org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:533)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:547)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:474)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)
	at util.HDFSWriter.writeToHDFS(HDFSWriter.java:21)
	at mapper.QuartetToTreeTablePartitionMapper.call(QuartetToTreeTablePartitionMapper.java:43)
	at org.apache.spark.sql.Dataset.$anonfun$mapPartitions$1(Dataset.scala:2820)
	at org.apache.spark.sql.execution.MapPartitionsExec.$anonfun$doExecute$3(objects.scala:195)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1423)
	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1350)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1414)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1237)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/11/10 00:59:21 ERROR StandaloneSchedulerBackend: Application has been killed. Reason: Master removed our application: KILLED
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Master removed our application: KILLED
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1079)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1079)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1079)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2445)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2261)
	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:414)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:1029)
	at org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:390)
	at org.apache.spark.sql.Dataset.$anonfun$count$1(Dataset.scala:3006)
	at org.apache.spark.sql.Dataset.$anonfun$count$1$adapted(Dataset.scala:3005)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)
	at org.apache.spark.sql.Dataset.count(Dataset.scala:3005)
	at algorithm.Distributer.runExplained(Distributer.java:96)
	at algorithm.Distributer.partitionDataAndRun(Distributer.java:137)
	at algorithm.Distributer.runFunctions(Distributer.java:32)
	at main.App.runwQFMSpark(App.java:24)
	at main.App.initializeAndRun(App.java:45)
	at main.App.main(App.java:59)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:951)
	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180)
	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203)
	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1039)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1048)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
21/11/10 00:59:21 ERROR Utils: Uncaught exception in thread stop-spark-context
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.deploy.client.StandaloneAppClient.stop(StandaloneAppClient.scala:287)
	at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.org$apache$spark$scheduler$cluster$StandaloneSchedulerBackend$$stop(StandaloneSchedulerBackend.scala:259)
	at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.stop(StandaloneSchedulerBackend.scala:131)
	at org.apache.spark.scheduler.TaskSchedulerImpl.stop(TaskSchedulerImpl.scala:881)
	at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2370)
	at org.apache.spark.SparkContext.$anonfun$stop$12(SparkContext.scala:2069)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1419)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anon$3.run(SparkContext.scala:2018)
Caused by: org.apache.spark.SparkException: Could not find AppClient.
	at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:176)
	at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:144)
	at org.apache.spark.rpc.netty.NettyRpcEnv.askAbortable(NettyRpcEnv.scala:242)
	at org.apache.spark.rpc.netty.NettyRpcEndpointRef.askAbortable(NettyRpcEnv.scala:555)
	at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:559)
	at org.apache.spark.rpc.RpcEndpointRef.ask(RpcEndpointRef.scala:74)
	... 9 more
21/11/10 00:59:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/11/10 00:59:32 INFO SparkContext: Running Spark version 3.1.2
21/11/10 00:59:32 INFO ResourceUtils: ==============================================================
21/11/10 00:59:32 INFO ResourceUtils: No custom resources configured for spark.driver.
21/11/10 00:59:32 INFO ResourceUtils: ==============================================================
21/11/10 00:59:32 INFO SparkContext: Submitted application: wQFMSpark
21/11/10 00:59:32 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 40960, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/11/10 00:59:32 INFO ResourceProfile: Limiting resource is cpu
21/11/10 00:59:32 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/11/10 00:59:32 INFO SecurityManager: Changing view acls to: kab076
21/11/10 00:59:32 INFO SecurityManager: Changing modify acls to: kab076
21/11/10 00:59:32 INFO SecurityManager: Changing view acls groups to: 
21/11/10 00:59:32 INFO SecurityManager: Changing modify acls groups to: 
21/11/10 00:59:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(kab076); groups with view permissions: Set(); users  with modify permissions: Set(kab076); groups with modify permissions: Set()
21/11/10 00:59:32 INFO Utils: Successfully started service 'sparkDriver' on port 37043.
21/11/10 00:59:32 INFO SparkEnv: Registering MapOutputTracker
21/11/10 00:59:32 INFO SparkEnv: Registering BlockManagerMaster
21/11/10 00:59:32 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/11/10 00:59:32 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/11/10 00:59:32 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/11/10 00:59:32 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-5b1006c2-bc67-4703-8967-2b3399853df7
21/11/10 00:59:32 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/11/10 00:59:32 INFO SparkEnv: Registering OutputCommitCoordinator
21/11/10 00:59:33 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/11/10 00:59:33 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://ms0819.utah.cloudlab.us:4040
21/11/10 00:59:33 INFO SparkContext: Added JAR file:/users/kab076/wQFMSpark/./target/wQFMSpark-1.0-SNAPSHOT-jar-with-dependencies.jar at spark://ms0819.utah.cloudlab.us:37043/jars/wQFMSpark-1.0-SNAPSHOT-jar-with-dependencies.jar with timestamp 1636531172139
21/11/10 00:59:33 INFO SparkContext: Added file file:///users/kab076/wQFMSpark/triplets.soda2103 at spark://ms0819.utah.cloudlab.us:37043/files/triplets.soda2103 with timestamp 1636531172139
21/11/10 00:59:33 INFO Utils: Copying /users/kab076/wQFMSpark/triplets.soda2103 to /tmp/spark-afca03ff-b52d-4d24-a186-3e838c6dde7e/userFiles-492ce5d4-df04-4ba3-a2d0-f35803c30195/triplets.soda2103
21/11/10 00:59:33 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://node0:7077...
21/11/10 00:59:33 INFO TransportClientFactory: Successfully created connection to node0/10.10.1.1:7077 after 56 ms (0 ms spent in bootstraps)
21/11/10 00:59:33 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211110005933-0036
21/11/10 00:59:33 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211110005933-0036/0 on worker-20211109002414-128.110.217.44-43329 (128.110.217.44:43329) with 16 core(s)
21/11/10 00:59:33 INFO StandaloneSchedulerBackend: Granted executor ID app-20211110005933-0036/0 on hostPort 128.110.217.44:43329 with 16 core(s), 40.0 GiB RAM
21/11/10 00:59:33 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211110005933-0036/1 on worker-20211109002452-128.110.217.51-42171 (128.110.217.51:42171) with 16 core(s)
21/11/10 00:59:33 INFO StandaloneSchedulerBackend: Granted executor ID app-20211110005933-0036/1 on hostPort 128.110.217.51:42171 with 16 core(s), 40.0 GiB RAM
21/11/10 00:59:33 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211110005933-0036/2 on worker-20211109002436-128.110.217.52-35535 (128.110.217.52:35535) with 16 core(s)
21/11/10 00:59:33 INFO StandaloneSchedulerBackend: Granted executor ID app-20211110005933-0036/2 on hostPort 128.110.217.52:35535 with 16 core(s), 40.0 GiB RAM
21/11/10 00:59:33 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37791.
21/11/10 00:59:33 INFO NettyBlockTransferService: Server created on ms0819.utah.cloudlab.us:37791
21/11/10 00:59:33 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/11/10 00:59:33 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211110005933-0036/0 is now RUNNING
21/11/10 00:59:33 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, ms0819.utah.cloudlab.us, 37791, None)
21/11/10 00:59:33 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211110005933-0036/2 is now RUNNING
21/11/10 00:59:33 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211110005933-0036/1 is now RUNNING
21/11/10 00:59:33 INFO BlockManagerMasterEndpoint: Registering block manager ms0819.utah.cloudlab.us:37791 with 398.7 MiB RAM, BlockManagerId(driver, ms0819.utah.cloudlab.us, 37791, None)
21/11/10 00:59:33 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, ms0819.utah.cloudlab.us, 37791, None)
21/11/10 00:59:33 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, ms0819.utah.cloudlab.us, 37791, None)
21/11/10 00:59:33 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
21/11/10 00:59:33 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
================= **** ========== Running wQFM on Spark ============== **** ====================
Final Taxa Table: TaxaTable{TAXA_COUNT=101,
 TAXA_LIST=[72, 97, 81, 90, 91, 92, 93, 94, 95, 96, 98, 99, 82, 83, 84, 85, 86, 87, 88, 89, 9, 73, 74, 75, 76, 77, 78, 79, 8, 80, 43, 65, 66, 44, 45, 46, 47, 48, 49, 5, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 6, 60, 61, 62, 63, 64, 67, 68, 69, 7, 70, 71, 38, 39, 4, 40, 41, 42, 21, 36, 37, 22, 23, 24, 25, 26, 27, 28, 29, 3, 30, 31, 32, 33, 34, 35, 17, 18, 19, 2, 20, 13, 14, 15, 16, 10, 100, 11, 12, 0, 1],
 TAXA_PARTITION_LIST Size=314}
+---+------+
|tag|count |
+---+------+
|296|5220  |
|125|2187  |
|51 |6630  |
|124|16784 |
|307|30    |
|169|33    |
|272|282   |
|234|26509 |
|232|194615|
|15 |8976  |
|282|78692 |
|11 |17463 |
|138|22122 |
|309|30    |
|112|829038|
|42 |3443  |
|308|30    |
|30 |8148  |
|113|82932 |
|34 |1062  |
+---+------+
only showing top 20 rows

+-----+-----+---+
|value|count|tag|
+-----+-----+---+
+-----+-----+---+

Number of Partitions by taxaPartition: 143
Number of Data Partitions: 3
Partitioning Tasks to workers ...
Total generated trees: 2
+----------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|support   |tag                                                                                                                                                                                                                                                                                                                                        |tree                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
+----------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|1.545783E9|230|195|192|193|191|199|198|197|149|148|147|151|153|139|140|138|141|137|136|134|135|119|115|118|120|117|114|113|122|124|125|116|126|123|169                                                                                                                                                                                                |((((56,(1,16)),(24,(33,((47,53),(52,(11,(37,62))))))),(86,(((76,81),(75,(77,73))),(((92,78),(99,96)),(((94,89),(80,100)),((84,(90,74)),((95,((91,97),(93,82))),((79,87),((83,88),(98,85)))))))))),((2,(15,(54,26,29))),((((10,(40,50,12)),(34,(68,(5,59)))),(((45,(35,14)),(48,(58,((49,41),(17,(31,25)))))),(20,((55,46),(70,(6,(32,(39,69)))))))),((7,(36,23,30)),(((4,13,28),((66,(51,(21,43))),((65,18),(42,72)))),(((22,(27,61)),((60,38),(44,(71,9)))),((3,(8,67)),(64,(57,(19,63))))))))));            |
|1.122681E9|288|291|295|287|286|285|284|283|282|290|293|292|289|294|251|252|300|311|306|305|304|303|302|312|301|43|50|48|47|46|45|44|299|297|309|308|307|49|298|296|269|268|267|266|41|37|265|38|272|271|270|264|259|260|258|257|256|262|255|34|33|36|32|253|248|249|42|244|243|242|240|239|238|246|247|235|236|234|231|232|245|241|237|233|250|263|261|((0,(((56,(16,1)),(24,(33,((52,(11,(62,37))),(47,53))))),(86,(((81,76),(75,(77,73))),(((78,92),(96,99)),(((89,94),(100,80)),((84,(74,90)),((95,((97,91),(82,93))),((79,87),((83,88),(98,85))))))))))),((2,(15,(54,(26,29)))),((((34,(68,(59,5))),(10,(50,(40,12)))),(((45,(14,35)),(48,(58,((41,49),(17,(31,25)))))),(20,((55,46),(70,(6,(32,(69,39)))))))),((7,(30,(36,23))),(((66,(51,(43,21))),((28,(13,4)),((65,18),(42,72)))),(((22,(27,61)),((60,38),(44,(9,71)))),((3,(67,8)),(64,(57,(19,63))))))))));|
+----------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

All partitioned Tasks Complete, Elapsed time: 716789
Final tree ((0,(((56,(16,1)),(24,(33,((52,(11,(62,37))),(47,53))))),(86,(((81,76),(75,(77,73))),(((78,92),(96,99)),(((89,94),(100,80)),((84,(74,90)),((95,((97,91),(82,93))),((79,87),((83,88),(98,85))))))))))),((2,(15,(54,(26,29)))),((((34,(68,(59,5))),(10,(50,(40,12)))),(((45,(14,35)),(48,(58,((41,49),(17,(31,25)))))),(20,((55,46),(70,(6,(32,(69,39)))))))),((7,(30,(36,23))),(((66,(51,(43,21))),((28,(13,4)),((65,18),(42,72)))),(((22,(27,61)),((60,38),(44,(9,71)))),((3,(67,8)),(64,(57,(19,63))))))))));
distributedRunTree: ((0,(((56,(16,1)),(24,(33,((52,(11,(62,37))),(47,53))))),(86,(((81,76),(75,(77,73))),(((78,92),(96,99)),(((89,94),(100,80)),((84,(74,90)),((95,((97,91),(82,93))),((79,87),((83,88),(98,85))))))))))),((2,(15,(54,(26,29)))),((((34,(68,(59,5))),(10,(50,(40,12)))),(((45,(14,35)),(48,(58,((41,49),(17,(31,25)))))),(20,((55,46),(70,(6,(32,(69,39)))))))),((7,(30,(36,23))),(((66,(51,(43,21))),((28,(13,4)),((65,18),(42,72)))),(((22,(27,61)),((60,38),(44,(9,71)))),((3,(67,8)),(64,(57,(19,63))))))))));

Time taken = 828624 ms ==> 13 minutes and 48 seconds.
================= **** ======================== **** ====================
21/11/10 01:17:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/11/10 01:17:58 INFO SparkContext: Running Spark version 3.1.2
21/11/10 01:17:58 INFO ResourceUtils: ==============================================================
21/11/10 01:17:58 INFO ResourceUtils: No custom resources configured for spark.driver.
21/11/10 01:17:58 INFO ResourceUtils: ==============================================================
21/11/10 01:17:58 INFO SparkContext: Submitted application: wQFMSpark
21/11/10 01:17:58 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 40960, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/11/10 01:17:58 INFO ResourceProfile: Limiting resource is cpu
21/11/10 01:17:58 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/11/10 01:17:58 INFO SecurityManager: Changing view acls to: kab076
21/11/10 01:17:58 INFO SecurityManager: Changing modify acls to: kab076
21/11/10 01:17:58 INFO SecurityManager: Changing view acls groups to: 
21/11/10 01:17:58 INFO SecurityManager: Changing modify acls groups to: 
21/11/10 01:17:58 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(kab076); groups with view permissions: Set(); users  with modify permissions: Set(kab076); groups with modify permissions: Set()
21/11/10 01:17:58 INFO Utils: Successfully started service 'sparkDriver' on port 35461.
21/11/10 01:17:58 INFO SparkEnv: Registering MapOutputTracker
21/11/10 01:17:58 INFO SparkEnv: Registering BlockManagerMaster
21/11/10 01:17:58 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/11/10 01:17:58 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/11/10 01:17:58 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/11/10 01:17:58 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-c1eb2a93-e25b-4c62-a03e-4ae69d5094f2
21/11/10 01:17:58 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/11/10 01:17:58 INFO SparkEnv: Registering OutputCommitCoordinator
21/11/10 01:17:59 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/11/10 01:17:59 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://ms0819.utah.cloudlab.us:4040
21/11/10 01:17:59 INFO SparkContext: Added JAR file:/users/kab076/wQFMSpark/./target/wQFMSpark-1.0-SNAPSHOT-jar-with-dependencies.jar at spark://ms0819.utah.cloudlab.us:35461/jars/wQFMSpark-1.0-SNAPSHOT-jar-with-dependencies.jar with timestamp 1636532278215
21/11/10 01:17:59 INFO SparkContext: Added file file:///users/kab076/wQFMSpark/triplets.soda2103 at spark://ms0819.utah.cloudlab.us:35461/files/triplets.soda2103 with timestamp 1636532278215
21/11/10 01:17:59 INFO Utils: Copying /users/kab076/wQFMSpark/triplets.soda2103 to /tmp/spark-7932f232-1032-49b5-a09f-f6eb95213cdc/userFiles-87b1d213-c3a6-4376-a599-10c919c59009/triplets.soda2103
21/11/10 01:17:59 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://node0:7077...
21/11/10 01:17:59 INFO TransportClientFactory: Successfully created connection to node0/10.10.1.1:7077 after 45 ms (0 ms spent in bootstraps)
21/11/10 01:17:59 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211110011759-0037
21/11/10 01:17:59 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211110011759-0037/0 on worker-20211109002414-128.110.217.44-43329 (128.110.217.44:43329) with 16 core(s)
21/11/10 01:17:59 INFO StandaloneSchedulerBackend: Granted executor ID app-20211110011759-0037/0 on hostPort 128.110.217.44:43329 with 16 core(s), 40.0 GiB RAM
21/11/10 01:17:59 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211110011759-0037/1 on worker-20211109002452-128.110.217.51-42171 (128.110.217.51:42171) with 16 core(s)
21/11/10 01:17:59 INFO StandaloneSchedulerBackend: Granted executor ID app-20211110011759-0037/1 on hostPort 128.110.217.51:42171 with 16 core(s), 40.0 GiB RAM
21/11/10 01:17:59 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211110011759-0037/2 on worker-20211109002436-128.110.217.52-35535 (128.110.217.52:35535) with 16 core(s)
21/11/10 01:17:59 INFO StandaloneSchedulerBackend: Granted executor ID app-20211110011759-0037/2 on hostPort 128.110.217.52:35535 with 16 core(s), 40.0 GiB RAM
21/11/10 01:17:59 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43789.
21/11/10 01:17:59 INFO NettyBlockTransferService: Server created on ms0819.utah.cloudlab.us:43789
21/11/10 01:17:59 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/11/10 01:17:59 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, ms0819.utah.cloudlab.us, 43789, None)
21/11/10 01:17:59 INFO BlockManagerMasterEndpoint: Registering block manager ms0819.utah.cloudlab.us:43789 with 398.7 MiB RAM, BlockManagerId(driver, ms0819.utah.cloudlab.us, 43789, None)
21/11/10 01:17:59 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211110011759-0037/0 is now RUNNING
21/11/10 01:17:59 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211110011759-0037/1 is now RUNNING
21/11/10 01:17:59 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, ms0819.utah.cloudlab.us, 43789, None)
21/11/10 01:17:59 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211110011759-0037/2 is now RUNNING
21/11/10 01:17:59 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, ms0819.utah.cloudlab.us, 43789, None)
21/11/10 01:18:00 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
21/11/10 01:18:00 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
================= **** ========== Running wQFM on Spark ============== **** ====================
Final Taxa Table: TaxaTable{TAXA_COUNT=101,
 TAXA_LIST=[72, 97, 81, 90, 91, 92, 93, 94, 95, 96, 98, 99, 82, 83, 84, 85, 86, 87, 88, 89, 9, 73, 74, 75, 76, 77, 78, 79, 8, 80, 61, 65, 66, 62, 63, 64, 67, 68, 69, 7, 70, 71, 43, 44, 45, 46, 47, 48, 49, 5, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 6, 60, 38, 39, 4, 40, 41, 42, 36, 37, 32, 34, 35, 33, 29, 3, 30, 31, 25, 26, 27, 28, 21, 22, 23, 24, 20, 18, 19, 2, 16, 17, 14, 15, 0, 1, 10, 100, 11, 12, 13],
 TAXA_PARTITION_LIST Size=1141}
+----+------+
|tag |count |
+----+------+
|829 |94877 |
|467 |12    |
|675 |510   |
|1090|18    |
|800 |935690|
|853 |1560  |
|870 |459   |
|926 |3     |
|613 |2757  |
|1043|15114 |
|205 |36    |
|1104|321   |
|647 |3378  |
|975 |1023  |
|442 |3     |
|1008|68716 |
|483 |36    |
|862 |135   |
|851 |2148  |
|635 |729   |
+----+------+
only showing top 20 rows

+-----+-----+---+
|value|count|tag|
+-----+-----+---+
+-----+-----+---+

Number of Partitions by taxaPartition: 413
Number of Data Partitions: 6
Partitioning Tasks to workers ...
21/11/10 01:29:53 WARN TaskSetManager: Lost task 1.0 in stage 17.0 (TID 553) (128.110.217.51 executor 1): org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.FSLimitException$PathComponentTooLongException): The maximum path component name limit of 1033|1064|1054|1049|1047|1045|1043|1041|1039|1037|1035|1053|1051|1099|1095|1076|1073|1070|1067|1031|1029|1058|1057|1028|1044|1061|1050|1042|1040|1032|1030|1036|1056|1048|1046|1038|1092|1034|1086|1088|1085|1022|1052|1027|1024|1020|1018|1016|1014|1026|1013|1011|1010|1008|1009|1007|1082|1055|1025|1021|1019|1017|1015|1059|1062|1060|1023|1091|1012|1074|1071|1066|1138|1120|1116|1108|1107|1104|1096|1089|1080|1083|1065|1123|1119|1115|1111|1103|1087|1081|1075|1072|1069|1094|1077|1125|1128|1122|1121|1118|1117|1114|1113|1110|1109|1106|1105|1102|1101|1098|1097|1090.wqrt in directory /user/kab076/exception is exceeded: limit=255 length=564
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyMaxComponentLength(FSDirectory.java:1186)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addLastINode(FSDirectory.java:1288)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addINode(FSDirectory.java:1113)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addFile(FSDirWriteFileOp.java:568)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:397)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2518)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2416)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:775)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:468)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy17.create(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:365)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy18.create(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:276)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1216)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1195)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1133)
	at org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:536)
	at org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:533)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:547)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:474)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)
	at util.HDFSWriter.writeToHDFS(HDFSWriter.java:21)
	at mapper.QuartetToTreeTablePartitionMapper.call(QuartetToTreeTablePartitionMapper.java:43)
	at org.apache.spark.sql.Dataset.$anonfun$mapPartitions$1(Dataset.scala:2820)
	at org.apache.spark.sql.execution.MapPartitionsExec.$anonfun$doExecute$3(objects.scala:195)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1423)
	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1350)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1414)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1237)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/11/10 01:36:48 WARN TaskSetManager: Lost task 1.1 in stage 17.0 (TID 558) (128.110.217.52 executor 2): org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.FSLimitException$PathComponentTooLongException): The maximum path component name limit of 1125|1128|1138|1120|1123|1122|1121|1119|1118|1117|1116|1115|1114|1113|1108|1111|1110|1109|1107|1106|1105|1104|1103|1102|1101|1099|1098|1097|1096|1095|1094|1092|1089|1091|1090|1080|1083|1082|1061|1060|1065|1059|1058|1053|1057|1028|1056|1055|1064|1054|1052|1051|1050|1049|1048|1047|1046|1045|1044|1043|1042|1041|1040|1039|1038|1037|1036|1035|1034|1033|1032|1031|1030|1029|1027|1026|1025|1024|1021|1022|1020|1019|1018|1017|1016|1015|1013|1014|1011|1010|1009|1008|1007|1076|1073|1070|1067|1088|1023|1085|1087|1066|1072|1069|1081|1075|1012|1086|1077|1074|1062|1071.wqrt in directory /user/kab076/exception is exceeded: limit=255 length=564
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyMaxComponentLength(FSDirectory.java:1186)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addLastINode(FSDirectory.java:1288)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addINode(FSDirectory.java:1113)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addFile(FSDirWriteFileOp.java:568)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:397)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2518)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2416)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:775)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:468)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy17.create(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:365)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy18.create(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:276)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1216)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1195)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1133)
	at org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:536)
	at org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:533)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:547)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:474)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)
	at util.HDFSWriter.writeToHDFS(HDFSWriter.java:21)
	at mapper.QuartetToTreeTablePartitionMapper.call(QuartetToTreeTablePartitionMapper.java:43)
	at org.apache.spark.sql.Dataset.$anonfun$mapPartitions$1(Dataset.scala:2820)
	at org.apache.spark.sql.execution.MapPartitionsExec.$anonfun$doExecute$3(objects.scala:195)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1423)
	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1350)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1414)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1237)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/11/10 01:39:10 ERROR StandaloneSchedulerBackend: Application has been killed. Reason: Master removed our application: KILLED
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Master removed our application: KILLED
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1079)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1079)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1079)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2445)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2261)
	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:414)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:1029)
	at org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:390)
	at org.apache.spark.sql.Dataset.$anonfun$count$1(Dataset.scala:3006)
	at org.apache.spark.sql.Dataset.$anonfun$count$1$adapted(Dataset.scala:3005)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)
	at org.apache.spark.sql.Dataset.count(Dataset.scala:3005)
	at algorithm.Distributer.runExplained(Distributer.java:96)
	at algorithm.Distributer.partitionDataAndRun(Distributer.java:137)
	at algorithm.Distributer.runFunctions(Distributer.java:32)
	at main.App.runwQFMSpark(App.java:24)
	at main.App.initializeAndRun(App.java:45)
	at main.App.main(App.java:59)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:951)
	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180)
	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203)
	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1039)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1048)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
21/11/10 01:39:10 ERROR Utils: Uncaught exception in thread stop-spark-context
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.deploy.client.StandaloneAppClient.stop(StandaloneAppClient.scala:287)
	at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.org$apache$spark$scheduler$cluster$StandaloneSchedulerBackend$$stop(StandaloneSchedulerBackend.scala:259)
	at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.stop(StandaloneSchedulerBackend.scala:131)
	at org.apache.spark.scheduler.TaskSchedulerImpl.stop(TaskSchedulerImpl.scala:881)
	at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2370)
	at org.apache.spark.SparkContext.$anonfun$stop$12(SparkContext.scala:2069)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1419)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anon$3.run(SparkContext.scala:2018)
Caused by: org.apache.spark.SparkException: Could not find AppClient.
	at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:176)
	at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:144)
	at org.apache.spark.rpc.netty.NettyRpcEnv.askAbortable(NettyRpcEnv.scala:242)
	at org.apache.spark.rpc.netty.NettyRpcEndpointRef.askAbortable(NettyRpcEnv.scala:555)
	at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:559)
	at org.apache.spark.rpc.RpcEndpointRef.ask(RpcEndpointRef.scala:74)
	... 9 more
21/11/10 01:40:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/11/10 01:40:18 INFO SparkContext: Running Spark version 3.1.2
21/11/10 01:40:18 INFO ResourceUtils: ==============================================================
21/11/10 01:40:18 INFO ResourceUtils: No custom resources configured for spark.driver.
21/11/10 01:40:18 INFO ResourceUtils: ==============================================================
21/11/10 01:40:18 INFO SparkContext: Submitted application: wQFMSpark
21/11/10 01:40:18 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 40960, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/11/10 01:40:18 INFO ResourceProfile: Limiting resource is cpu
21/11/10 01:40:18 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/11/10 01:40:18 INFO SecurityManager: Changing view acls to: kab076
21/11/10 01:40:18 INFO SecurityManager: Changing modify acls to: kab076
21/11/10 01:40:18 INFO SecurityManager: Changing view acls groups to: 
21/11/10 01:40:18 INFO SecurityManager: Changing modify acls groups to: 
21/11/10 01:40:18 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(kab076); groups with view permissions: Set(); users  with modify permissions: Set(kab076); groups with modify permissions: Set()
21/11/10 01:40:19 INFO Utils: Successfully started service 'sparkDriver' on port 45957.
21/11/10 01:40:19 INFO SparkEnv: Registering MapOutputTracker
21/11/10 01:40:19 INFO SparkEnv: Registering BlockManagerMaster
21/11/10 01:40:19 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/11/10 01:40:19 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/11/10 01:40:19 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/11/10 01:40:19 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-56355bf4-979f-4cbd-8c86-eca12f4c5ef4
21/11/10 01:40:19 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/11/10 01:40:19 INFO SparkEnv: Registering OutputCommitCoordinator
21/11/10 01:40:19 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/11/10 01:40:19 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://ms0819.utah.cloudlab.us:4040
21/11/10 01:40:19 INFO SparkContext: Added JAR file:/users/kab076/wQFMSpark/./target/wQFMSpark-1.0-SNAPSHOT-jar-with-dependencies.jar at spark://ms0819.utah.cloudlab.us:45957/jars/wQFMSpark-1.0-SNAPSHOT-jar-with-dependencies.jar with timestamp 1636533618694
21/11/10 01:40:19 INFO SparkContext: Added file file:///users/kab076/wQFMSpark/triplets.soda2103 at spark://ms0819.utah.cloudlab.us:45957/files/triplets.soda2103 with timestamp 1636533618694
21/11/10 01:40:19 INFO Utils: Copying /users/kab076/wQFMSpark/triplets.soda2103 to /tmp/spark-33100b29-fad6-42a4-8935-ddfbfb51d522/userFiles-fbe9a913-b936-4515-88df-8b013a869c83/triplets.soda2103
21/11/10 01:40:19 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://node0:7077...
21/11/10 01:40:20 INFO TransportClientFactory: Successfully created connection to node0/10.10.1.1:7077 after 45 ms (0 ms spent in bootstraps)
21/11/10 01:40:20 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211110014020-0038
21/11/10 01:40:20 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211110014020-0038/0 on worker-20211109002414-128.110.217.44-43329 (128.110.217.44:43329) with 16 core(s)
21/11/10 01:40:20 INFO StandaloneSchedulerBackend: Granted executor ID app-20211110014020-0038/0 on hostPort 128.110.217.44:43329 with 16 core(s), 40.0 GiB RAM
21/11/10 01:40:20 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211110014020-0038/1 on worker-20211109002452-128.110.217.51-42171 (128.110.217.51:42171) with 16 core(s)
21/11/10 01:40:20 INFO StandaloneSchedulerBackend: Granted executor ID app-20211110014020-0038/1 on hostPort 128.110.217.51:42171 with 16 core(s), 40.0 GiB RAM
21/11/10 01:40:20 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211110014020-0038/2 on worker-20211109002436-128.110.217.52-35535 (128.110.217.52:35535) with 16 core(s)
21/11/10 01:40:20 INFO StandaloneSchedulerBackend: Granted executor ID app-20211110014020-0038/2 on hostPort 128.110.217.52:35535 with 16 core(s), 40.0 GiB RAM
21/11/10 01:40:20 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41983.
21/11/10 01:40:20 INFO NettyBlockTransferService: Server created on ms0819.utah.cloudlab.us:41983
21/11/10 01:40:20 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/11/10 01:40:20 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, ms0819.utah.cloudlab.us, 41983, None)
21/11/10 01:40:20 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211110014020-0038/1 is now RUNNING
21/11/10 01:40:20 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211110014020-0038/2 is now RUNNING
21/11/10 01:40:20 INFO BlockManagerMasterEndpoint: Registering block manager ms0819.utah.cloudlab.us:41983 with 398.7 MiB RAM, BlockManagerId(driver, ms0819.utah.cloudlab.us, 41983, None)
21/11/10 01:40:20 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211110014020-0038/0 is now RUNNING
21/11/10 01:40:20 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, ms0819.utah.cloudlab.us, 41983, None)
21/11/10 01:40:20 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, ms0819.utah.cloudlab.us, 41983, None)
21/11/10 01:40:20 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
21/11/10 01:40:20 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
================= **** ========== Running wQFM on Spark ============== **** ====================
Final Taxa Table: TaxaTable{TAXA_COUNT=101,
 TAXA_LIST=[72, 97, 81, 90, 91, 92, 93, 94, 95, 96, 98, 99, 82, 83, 84, 85, 86, 87, 88, 89, 9, 73, 74, 75, 76, 77, 78, 79, 8, 80, 38, 50, 51, 39, 4, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 5, 52, 53, 54, 55, 56, 57, 58, 59, 6, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 7, 70, 71, 33, 34, 35, 36, 37, 3, 30, 31, 32, 28, 29, 26, 27, 21, 22, 23, 24, 25, 18, 19, 2, 20, 15, 16, 17, 14, 11, 12, 13, 1, 10, 100, 0],
 TAXA_PARTITION_LIST Size=1140}
+----+------+
|tag |count |
+----+------+
|691 |4176  |
|675 |768   |
|829 |45996 |
|944 |330   |
|853 |11776 |
|800 |874207|
|451 |168   |
|666 |7554  |
|447 |48    |
|7   |10346 |
|613 |1281  |
|718 |726   |
|475 |6     |
|1043|18691 |
|711 |1900  |
|647 |14712 |
|272 |221   |
|442 |3     |
|1008|12678 |
|700 |3866  |
+----+------+
only showing top 20 rows

+-----+-----+---+
|value|count|tag|
+-----+-----+---+
+-----+-----+---+

Number of Partitions by taxaPartition: 442
Number of Data Partitions: 48
Partitioning Tasks to workers ...
21/11/10 01:46:12 WARN TaskSetManager: Lost task 47.0 in stage 17.0 (TID 594) (128.110.217.52 executor 2): org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.FSLimitException$PathComponentTooLongException): The maximum path component name limit of 950|964|942|934|961|958|931|930|929|928|962|960|954|957|956|955|953|952|951|946|949|948|947|945|944|943|938|941|940|939|937|936|935|933|965|932|963|899|898|897|896|895|894|893|892|902|924|880|868|867|866|865|864|863|862|859|858|857|875|861|860|876|884|883|882|881|890|879|874|970|971|968|973|969|972|887|886|885|888|889|869|872|871|873.wqrt in directory /user/kab076/exception is exceeded: limit=255 length=340
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyMaxComponentLength(FSDirectory.java:1186)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addLastINode(FSDirectory.java:1288)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addINode(FSDirectory.java:1113)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addFile(FSDirWriteFileOp.java:568)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:397)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2518)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2416)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:775)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:468)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy17.create(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:365)
	at sun.reflect.GeneratedMethodAccessor177.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy18.create(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:276)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1216)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1195)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1133)
	at org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:536)
	at org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:533)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:547)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:474)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)
	at util.HDFSWriter.writeToHDFS(HDFSWriter.java:21)
	at mapper.QuartetToTreeTablePartitionMapper.call(QuartetToTreeTablePartitionMapper.java:43)
	at org.apache.spark.sql.Dataset.$anonfun$mapPartitions$1(Dataset.scala:2820)
	at org.apache.spark.sql.execution.MapPartitionsExec.$anonfun$doExecute$3(objects.scala:195)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1423)
	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1350)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1414)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1237)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/11/10 01:47:09 WARN TaskSetManager: Lost task 47.1 in stage 17.0 (TID 595) (128.110.217.51 executor 1): org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.FSLimitException$PathComponentTooLongException): The maximum path component name limit of 970|971|968|965|973|964|963|961|962|958|960|954|957|956|955|950|953|952|951|946|949|948|947|942|945|944|943|938|941|940|939|934|937|936|935|933|932|931|930|929|928|969|972|894|895|896|899|898|897|890|887|886|885|884|883|882|881|880|888|889|879|876|875|869|868|867|866|865|864|863|862|861|860|859|858|857|874|872|871|873|892|893|924|902.wqrt in directory /user/kab076/exception is exceeded: limit=255 length=340
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyMaxComponentLength(FSDirectory.java:1186)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addLastINode(FSDirectory.java:1288)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addINode(FSDirectory.java:1113)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addFile(FSDirWriteFileOp.java:568)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:397)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2518)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2416)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:775)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:468)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy17.create(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:365)
	at sun.reflect.GeneratedMethodAccessor196.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy18.create(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:276)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1216)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1195)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1133)
	at org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:536)
	at org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:533)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:547)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:474)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)
	at util.HDFSWriter.writeToHDFS(HDFSWriter.java:21)
	at mapper.QuartetToTreeTablePartitionMapper.call(QuartetToTreeTablePartitionMapper.java:43)
	at org.apache.spark.sql.Dataset.$anonfun$mapPartitions$1(Dataset.scala:2820)
	at org.apache.spark.sql.execution.MapPartitionsExec.$anonfun$doExecute$3(objects.scala:195)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1423)
	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1350)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1414)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1237)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/11/10 01:47:42 WARN TaskSetManager: Lost task 47.2 in stage 17.0 (TID 596) (128.110.217.51 executor 1): org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.FSLimitException$PathComponentTooLongException): The maximum path component name limit of 970|971|968|965|973|964|963|961|962|958|960|954|957|956|955|950|953|952|951|946|949|948|947|942|945|944|943|938|941|940|939|934|937|936|935|933|932|931|930|929|928|969|972|894|895|896|899|898|897|890|887|886|885|884|883|882|881|880|888|889|879|876|875|869|868|867|866|865|864|863|862|861|860|859|858|857|874|872|871|873|892|893|924|902.wqrt in directory /user/kab076/exception is exceeded: limit=255 length=340
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyMaxComponentLength(FSDirectory.java:1186)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addLastINode(FSDirectory.java:1288)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addINode(FSDirectory.java:1113)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addFile(FSDirWriteFileOp.java:568)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:397)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2518)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2416)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:775)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:468)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy17.create(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:365)
	at sun.reflect.GeneratedMethodAccessor196.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy18.create(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:276)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1216)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1195)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1133)
	at org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:536)
	at org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:533)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:547)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:474)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)
	at util.HDFSWriter.writeToHDFS(HDFSWriter.java:21)
	at mapper.QuartetToTreeTablePartitionMapper.call(QuartetToTreeTablePartitionMapper.java:43)
	at org.apache.spark.sql.Dataset.$anonfun$mapPartitions$1(Dataset.scala:2820)
	at org.apache.spark.sql.execution.MapPartitionsExec.$anonfun$doExecute$3(objects.scala:195)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1423)
	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1350)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1414)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1237)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/11/10 01:48:23 WARN TaskSetManager: Lost task 47.3 in stage 17.0 (TID 597) (128.110.217.51 executor 1): org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.FSLimitException$PathComponentTooLongException): The maximum path component name limit of 970|971|968|965|973|964|963|961|962|958|960|954|957|956|955|950|953|952|951|946|949|948|947|942|945|944|943|938|941|940|939|934|937|936|935|933|932|931|930|929|928|969|972|894|895|896|899|898|897|890|887|886|885|884|883|882|881|880|888|889|879|876|875|869|868|867|866|865|864|863|862|861|860|859|858|857|874|872|871|873|892|893|924|902.wqrt in directory /user/kab076/exception is exceeded: limit=255 length=340
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyMaxComponentLength(FSDirectory.java:1186)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addLastINode(FSDirectory.java:1288)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addINode(FSDirectory.java:1113)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addFile(FSDirWriteFileOp.java:568)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:397)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2518)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2416)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:775)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:468)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy17.create(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:365)
	at sun.reflect.GeneratedMethodAccessor196.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy18.create(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:276)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1216)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1195)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1133)
	at org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:536)
	at org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:533)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:547)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:474)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)
	at util.HDFSWriter.writeToHDFS(HDFSWriter.java:21)
	at mapper.QuartetToTreeTablePartitionMapper.call(QuartetToTreeTablePartitionMapper.java:43)
	at org.apache.spark.sql.Dataset.$anonfun$mapPartitions$1(Dataset.scala:2820)
	at org.apache.spark.sql.execution.MapPartitionsExec.$anonfun$doExecute$3(objects.scala:195)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1423)
	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1350)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1414)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1237)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/11/10 01:48:23 ERROR TaskSetManager: Task 47 in stage 17.0 failed 4 times; aborting job
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 47 in stage 17.0 failed 4 times, most recent failure: Lost task 47.3 in stage 17.0 (TID 597) (128.110.217.51 executor 1): org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.FSLimitException$PathComponentTooLongException): The maximum path component name limit of 970|971|968|965|973|964|963|961|962|958|960|954|957|956|955|950|953|952|951|946|949|948|947|942|945|944|943|938|941|940|939|934|937|936|935|933|932|931|930|929|928|969|972|894|895|896|899|898|897|890|887|886|885|884|883|882|881|880|888|889|879|876|875|869|868|867|866|865|864|863|862|861|860|859|858|857|874|872|871|873|892|893|924|902.wqrt in directory /user/kab076/exception is exceeded: limit=255 length=340
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyMaxComponentLength(FSDirectory.java:1186)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addLastINode(FSDirectory.java:1288)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addINode(FSDirectory.java:1113)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addFile(FSDirWriteFileOp.java:568)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:397)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2518)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2416)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:775)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:468)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy17.create(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:365)
	at sun.reflect.GeneratedMethodAccessor196.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy18.create(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:276)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1216)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1195)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1133)
	at org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:536)
	at org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:533)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:547)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:474)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)
	at util.HDFSWriter.writeToHDFS(HDFSWriter.java:21)
	at mapper.QuartetToTreeTablePartitionMapper.call(QuartetToTreeTablePartitionMapper.java:43)
	at org.apache.spark.sql.Dataset.$anonfun$mapPartitions$1(Dataset.scala:2820)
	at org.apache.spark.sql.execution.MapPartitionsExec.$anonfun$doExecute$3(objects.scala:195)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1423)
	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1350)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1414)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1237)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1079)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1079)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1079)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2445)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2261)
	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:414)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:1029)
	at org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:390)
	at org.apache.spark.sql.Dataset.$anonfun$count$1(Dataset.scala:3006)
	at org.apache.spark.sql.Dataset.$anonfun$count$1$adapted(Dataset.scala:3005)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)
	at org.apache.spark.sql.Dataset.count(Dataset.scala:3005)
	at algorithm.Distributer.runExplained(Distributer.java:96)
	at algorithm.Distributer.partitionDataAndRun(Distributer.java:137)
	at algorithm.Distributer.runFunctions(Distributer.java:32)
	at main.App.runwQFMSpark(App.java:24)
	at main.App.initializeAndRun(App.java:45)
	at main.App.main(App.java:59)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:951)
	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180)
	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203)
	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1039)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1048)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.FSLimitException$PathComponentTooLongException): The maximum path component name limit of 970|971|968|965|973|964|963|961|962|958|960|954|957|956|955|950|953|952|951|946|949|948|947|942|945|944|943|938|941|940|939|934|937|936|935|933|932|931|930|929|928|969|972|894|895|896|899|898|897|890|887|886|885|884|883|882|881|880|888|889|879|876|875|869|868|867|866|865|864|863|862|861|860|859|858|857|874|872|871|873|892|893|924|902.wqrt in directory /user/kab076/exception is exceeded: limit=255 length=340
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyMaxComponentLength(FSDirectory.java:1186)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addLastINode(FSDirectory.java:1288)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addINode(FSDirectory.java:1113)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addFile(FSDirWriteFileOp.java:568)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:397)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2518)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2416)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:775)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:468)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy17.create(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:365)
	at sun.reflect.GeneratedMethodAccessor196.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy18.create(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:276)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1216)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1195)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1133)
	at org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:536)
	at org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:533)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:547)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:474)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)
	at util.HDFSWriter.writeToHDFS(HDFSWriter.java:21)
	at mapper.QuartetToTreeTablePartitionMapper.call(QuartetToTreeTablePartitionMapper.java:43)
	at org.apache.spark.sql.Dataset.$anonfun$mapPartitions$1(Dataset.scala:2820)
	at org.apache.spark.sql.execution.MapPartitionsExec.$anonfun$doExecute$3(objects.scala:195)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1423)
	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1350)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1414)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1237)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/11/10 01:55:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/11/10 01:55:22 INFO SparkContext: Running Spark version 3.1.2
21/11/10 01:55:22 INFO ResourceUtils: ==============================================================
21/11/10 01:55:22 INFO ResourceUtils: No custom resources configured for spark.driver.
21/11/10 01:55:22 INFO ResourceUtils: ==============================================================
21/11/10 01:55:22 INFO SparkContext: Submitted application: wQFMSpark
21/11/10 01:55:22 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 40960, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/11/10 01:55:22 INFO ResourceProfile: Limiting resource is cpu
21/11/10 01:55:22 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/11/10 01:55:23 INFO SecurityManager: Changing view acls to: kab076
21/11/10 01:55:23 INFO SecurityManager: Changing modify acls to: kab076
21/11/10 01:55:23 INFO SecurityManager: Changing view acls groups to: 
21/11/10 01:55:23 INFO SecurityManager: Changing modify acls groups to: 
21/11/10 01:55:23 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(kab076); groups with view permissions: Set(); users  with modify permissions: Set(kab076); groups with modify permissions: Set()
21/11/10 01:55:23 INFO Utils: Successfully started service 'sparkDriver' on port 39647.
21/11/10 01:55:23 INFO SparkEnv: Registering MapOutputTracker
21/11/10 01:55:23 INFO SparkEnv: Registering BlockManagerMaster
21/11/10 01:55:23 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/11/10 01:55:23 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/11/10 01:55:23 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/11/10 01:55:23 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-cd761a5b-cd78-4263-85e4-8239a54254ba
21/11/10 01:55:23 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/11/10 01:55:23 INFO SparkEnv: Registering OutputCommitCoordinator
21/11/10 01:55:23 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/11/10 01:55:23 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://ms0819.utah.cloudlab.us:4040
21/11/10 01:55:23 INFO SparkContext: Added JAR file:/users/kab076/wQFMSpark/./target/wQFMSpark-1.0-SNAPSHOT-jar-with-dependencies.jar at spark://ms0819.utah.cloudlab.us:39647/jars/wQFMSpark-1.0-SNAPSHOT-jar-with-dependencies.jar with timestamp 1636534522856
21/11/10 01:55:23 INFO SparkContext: Added file file:///users/kab076/wQFMSpark/triplets.soda2103 at spark://ms0819.utah.cloudlab.us:39647/files/triplets.soda2103 with timestamp 1636534522856
21/11/10 01:55:23 INFO Utils: Copying /users/kab076/wQFMSpark/triplets.soda2103 to /tmp/spark-6407ff80-4701-4a64-a923-d44e66ba304f/userFiles-a9363863-c1d4-40d5-a93d-edf2fe275f7a/triplets.soda2103
21/11/10 01:55:23 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://node0:7077...
21/11/10 01:55:24 INFO TransportClientFactory: Successfully created connection to node0/10.10.1.1:7077 after 45 ms (0 ms spent in bootstraps)
21/11/10 01:55:24 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211110015524-0039
21/11/10 01:55:24 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211110015524-0039/0 on worker-20211109002414-128.110.217.44-43329 (128.110.217.44:43329) with 16 core(s)
21/11/10 01:55:24 INFO StandaloneSchedulerBackend: Granted executor ID app-20211110015524-0039/0 on hostPort 128.110.217.44:43329 with 16 core(s), 40.0 GiB RAM
21/11/10 01:55:24 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211110015524-0039/1 on worker-20211109002452-128.110.217.51-42171 (128.110.217.51:42171) with 16 core(s)
21/11/10 01:55:24 INFO StandaloneSchedulerBackend: Granted executor ID app-20211110015524-0039/1 on hostPort 128.110.217.51:42171 with 16 core(s), 40.0 GiB RAM
21/11/10 01:55:24 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211110015524-0039/2 on worker-20211109002436-128.110.217.52-35535 (128.110.217.52:35535) with 16 core(s)
21/11/10 01:55:24 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41031.
21/11/10 01:55:24 INFO NettyBlockTransferService: Server created on ms0819.utah.cloudlab.us:41031
21/11/10 01:55:24 INFO StandaloneSchedulerBackend: Granted executor ID app-20211110015524-0039/2 on hostPort 128.110.217.52:35535 with 16 core(s), 40.0 GiB RAM
21/11/10 01:55:24 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/11/10 01:55:24 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, ms0819.utah.cloudlab.us, 41031, None)
21/11/10 01:55:24 INFO BlockManagerMasterEndpoint: Registering block manager ms0819.utah.cloudlab.us:41031 with 398.7 MiB RAM, BlockManagerId(driver, ms0819.utah.cloudlab.us, 41031, None)
21/11/10 01:55:24 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211110015524-0039/2 is now RUNNING
21/11/10 01:55:24 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211110015524-0039/1 is now RUNNING
21/11/10 01:55:24 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, ms0819.utah.cloudlab.us, 41031, None)
21/11/10 01:55:24 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, ms0819.utah.cloudlab.us, 41031, None)
21/11/10 01:55:24 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211110015524-0039/0 is now RUNNING
21/11/10 01:55:24 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
21/11/10 01:55:24 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
================= **** ========== Running wQFM on Spark ============== **** ====================
Final Taxa Table: TaxaTable{TAXA_COUNT=101,
 TAXA_LIST=[72, 97, 81, 90, 91, 92, 93, 94, 95, 96, 98, 99, 82, 83, 84, 85, 86, 87, 88, 89, 9, 73, 74, 75, 76, 77, 78, 79, 8, 80, 23, 68, 69, 7, 70, 71, 24, 25, 26, 27, 28, 29, 3, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 4, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 5, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 6, 60, 61, 62, 63, 64, 65, 66, 67, 17, 18, 19, 2, 20, 21, 22, 13, 14, 15, 16, 10, 100, 11, 12, 1, 0],
 TAXA_PARTITION_LIST Size=313}
+---+------+
|tag|count |
+---+------+
|7  |13406 |
|272|3707  |
|282|17571 |
|234|157907|
|232|158326|
|15 |2604  |
|132|6289  |
|11 |78280 |
|279|78692 |
|29 |22832 |
|112|68979 |
|87 |135   |
|64 |72    |
|3  |629   |
|113|292970|
|30 |3259  |
|34 |630   |
|133|4472  |
|287|29630 |
|59 |2448  |
+---+------+
only showing top 20 rows

+-----+-----+---+
|value|count|tag|
+-----+-----+---+
+-----+-----+---+

Number of Partitions by taxaPartition: 159
Number of Data Partitions: 48
Partitioning Tasks to workers ...
21/11/10 01:57:49 ERROR TaskSchedulerImpl: Lost executor 0 on 128.110.217.44: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
21/11/10 01:57:49 WARN TaskSetManager: Lost task 46.0 in stage 17.0 (TID 609) (128.110.217.44 executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
21/11/10 01:57:49 WARN TaskSetManager: Lost task 38.0 in stage 17.0 (TID 600) (128.110.217.44 executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
21/11/10 01:57:49 WARN TaskSetManager: Lost task 5.0 in stage 17.0 (TID 567) (128.110.217.44 executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
21/11/10 01:57:49 WARN TaskSetManager: Lost task 41.0 in stage 17.0 (TID 603) (128.110.217.44 executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
21/11/10 01:57:49 WARN TaskSetManager: Lost task 14.0 in stage 17.0 (TID 576) (128.110.217.44 executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
21/11/10 01:57:49 WARN TaskSetManager: Lost task 32.0 in stage 17.0 (TID 594) (128.110.217.44 executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
21/11/10 01:57:49 WARN TaskSetManager: Lost task 24.0 in stage 17.0 (TID 585) (128.110.217.44 executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
21/11/10 01:57:49 WARN TaskSetManager: Lost task 44.0 in stage 17.0 (TID 606) (128.110.217.44 executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
21/11/10 01:57:49 WARN TaskSetManager: Lost task 33.0 in stage 17.0 (TID 597) (128.110.217.44 executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
21/11/10 01:57:49 WARN TaskSetManager: Lost task 17.0 in stage 17.0 (TID 579) (128.110.217.44 executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
21/11/10 01:57:49 WARN TaskSetManager: Lost task 25.0 in stage 17.0 (TID 588) (128.110.217.44 executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
21/11/10 01:57:49 WARN TaskSetManager: Lost task 8.0 in stage 17.0 (TID 570) (128.110.217.44 executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
21/11/10 01:57:49 WARN TaskSetManager: Lost task 12.0 in stage 17.0 (TID 573) (128.110.217.44 executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
21/11/10 01:57:49 WARN TaskSetManager: Lost task 3.0 in stage 17.0 (TID 564) (128.110.217.44 executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
21/11/10 01:57:49 WARN TaskSetManager: Lost task 31.0 in stage 17.0 (TID 591) (128.110.217.44 executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
21/11/10 01:57:49 WARN TaskSetManager: Lost task 21.0 in stage 17.0 (TID 582) (128.110.217.44 executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
21/11/10 01:57:49 WARN TaskSetManager: Lost task 31.1 in stage 17.0 (TID 610) (128.110.217.51 executor 1): FetchFailed(BlockManagerId(0, 128.110.217.44, 38711, None), shuffleId=4, mapIndex=6, mapId=520, reduceId=31, message=
org.apache.spark.shuffle.FetchFailedException: The relative remote executor(Id: 0), which maintains the block data to fetch is dead.
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:770)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:685)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)
	at org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)
	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at scala.collection.convert.Wrappers$IteratorWrapper.hasNext(Wrappers.scala:31)
	at mapper.QuartetToTreeTablePartitionMapper.call(QuartetToTreeTablePartitionMapper.java:24)
	at org.apache.spark.sql.Dataset.$anonfun$mapPartitions$1(Dataset.scala:2820)
	at org.apache.spark.sql.execution.MapPartitionsExec.$anonfun$doExecute$3(objects.scala:195)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1423)
	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1350)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1414)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1237)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.ExecutorDeadException: The relative remote executor(Id: 0), which maintains the block data to fetch is dead.
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:133)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.start(RetryingBlockFetcher.java:133)
	at org.apache.spark.network.netty.NettyBlockTransferService.fetchBlocks(NettyBlockTransferService.scala:143)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.sendRequest(ShuffleBlockFetcherIterator.scala:283)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.send$1(ShuffleBlockFetcherIterator.scala:743)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchUpToMaxBytes(ShuffleBlockFetcherIterator.scala:738)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:552)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:171)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:85)
	at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:212)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	... 43 more

)
21/11/10 01:57:49 WARN TaskSetManager: Lost task 3.1 in stage 17.0 (TID 611) (128.110.217.51 executor 1): FetchFailed(BlockManagerId(0, 128.110.217.44, 38711, None), shuffleId=4, mapIndex=18, mapId=532, reduceId=3, message=
org.apache.spark.shuffle.FetchFailedException: The relative remote executor(Id: 0), which maintains the block data to fetch is dead.
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:770)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:685)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)
	at org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)
	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at scala.collection.convert.Wrappers$IteratorWrapper.hasNext(Wrappers.scala:31)
	at mapper.QuartetToTreeTablePartitionMapper.call(QuartetToTreeTablePartitionMapper.java:24)
	at org.apache.spark.sql.Dataset.$anonfun$mapPartitions$1(Dataset.scala:2820)
	at org.apache.spark.sql.execution.MapPartitionsExec.$anonfun$doExecute$3(objects.scala:195)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1423)
	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1350)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1414)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1237)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.ExecutorDeadException: The relative remote executor(Id: 0), which maintains the block data to fetch is dead.
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:133)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.start(RetryingBlockFetcher.java:133)
	at org.apache.spark.network.netty.NettyBlockTransferService.fetchBlocks(NettyBlockTransferService.scala:143)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.sendRequest(ShuffleBlockFetcherIterator.scala:283)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.send$1(ShuffleBlockFetcherIterator.scala:743)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchUpToMaxBytes(ShuffleBlockFetcherIterator.scala:738)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:552)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:171)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:85)
	at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:212)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	... 43 more

)
21/11/10 01:57:52 WARN TaskSetManager: Lost task 1.0 in stage 16.1 (TID 613) (128.110.217.52 executor 2): org.apache.spark.util.TaskCompletionListenerException: Filesystem closed

Previous exception in task: Filesystem closed
	org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:474)
	org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:742)
	org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:829)
	java.io.DataInputStream.read(DataInputStream.java:149)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)
	org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:218)
	org.apache.hadoop.util.LineReader.readLine(LineReader.java:176)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)
	org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:194)
	org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:37)
	org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.hasNext(HadoopFileLinesReader.scala:69)
	scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:511)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:489)
	scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:93)
	scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)
	scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:155)
	org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
	org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	org.apache.spark.scheduler.Task.run(Task.scala:131)
	org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	java.lang.Thread.run(Thread.java:748)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:145)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:124)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/11/10 01:57:55 ERROR TaskSetManager: Task 2 in stage 16.1 failed 4 times; aborting job
21/11/10 01:57:55 WARN TaskSetManager: Lost task 4.3 in stage 16.1 (TID 640) (128.110.217.52 executor 2): TaskKilled (Stage cancelled)
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 2 in stage 16.1 failed 4 times, most recent failure: Lost task 2.3 in stage 16.1 (TID 639) (128.110.217.51 executor 1): org.apache.spark.util.TaskCompletionListenerException: Filesystem closed

Previous exception in task: Filesystem closed
	org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:474)
	org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:742)
	org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:829)
	java.io.DataInputStream.read(DataInputStream.java:149)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)
	org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:218)
	org.apache.hadoop.util.LineReader.readLine(LineReader.java:176)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)
	org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:194)
	org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:37)
	org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.hasNext(HadoopFileLinesReader.scala:69)
	scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:511)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:489)
	scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:93)
	scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)
	scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:155)
	org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
	org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	org.apache.spark.scheduler.Task.run(Task.scala:131)
	org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	java.lang.Thread.run(Thread.java:748)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:145)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:124)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1079)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1079)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1079)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2445)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2261)
	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:414)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:1029)
	at org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:390)
	at org.apache.spark.sql.Dataset.$anonfun$count$1(Dataset.scala:3006)
	at org.apache.spark.sql.Dataset.$anonfun$count$1$adapted(Dataset.scala:3005)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)
	at org.apache.spark.sql.Dataset.count(Dataset.scala:3005)
	at algorithm.Distributer.runExplained(Distributer.java:96)
	at algorithm.Distributer.partitionDataAndRun(Distributer.java:137)
	at algorithm.Distributer.runFunctions(Distributer.java:32)
	at main.App.runwQFMSpark(App.java:24)
	at main.App.initializeAndRun(App.java:45)
	at main.App.main(App.java:59)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:951)
	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180)
	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203)
	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1039)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1048)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Caused by: org.apache.spark.util.TaskCompletionListenerException: Filesystem closed

Previous exception in task: Filesystem closed
	org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:474)
	org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:742)
	org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:829)
	java.io.DataInputStream.read(DataInputStream.java:149)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)
	org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:218)
	org.apache.hadoop.util.LineReader.readLine(LineReader.java:176)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)
	org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:194)
	org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:37)
	org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.hasNext(HadoopFileLinesReader.scala:69)
	scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:511)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:489)
	scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:93)
	scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)
	scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:155)
	org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
	org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	org.apache.spark.scheduler.Task.run(Task.scala:131)
	org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	java.lang.Thread.run(Thread.java:748)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:145)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:124)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/11/10 02:07:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/11/10 02:07:30 INFO SparkContext: Running Spark version 3.1.2
21/11/10 02:07:30 INFO ResourceUtils: ==============================================================
21/11/10 02:07:30 INFO ResourceUtils: No custom resources configured for spark.driver.
21/11/10 02:07:30 INFO ResourceUtils: ==============================================================
21/11/10 02:07:30 INFO SparkContext: Submitted application: wQFMSpark
21/11/10 02:07:30 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 40960, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/11/10 02:07:30 INFO ResourceProfile: Limiting resource is cpu
21/11/10 02:07:30 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/11/10 02:07:30 INFO SecurityManager: Changing view acls to: kab076
21/11/10 02:07:30 INFO SecurityManager: Changing modify acls to: kab076
21/11/10 02:07:30 INFO SecurityManager: Changing view acls groups to: 
21/11/10 02:07:30 INFO SecurityManager: Changing modify acls groups to: 
21/11/10 02:07:30 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(kab076); groups with view permissions: Set(); users  with modify permissions: Set(kab076); groups with modify permissions: Set()
21/11/10 02:07:31 INFO Utils: Successfully started service 'sparkDriver' on port 34969.
21/11/10 02:07:31 INFO SparkEnv: Registering MapOutputTracker
21/11/10 02:07:31 INFO SparkEnv: Registering BlockManagerMaster
21/11/10 02:07:31 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/11/10 02:07:31 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/11/10 02:07:31 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/11/10 02:07:31 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-ce9fd1d9-8cfa-4037-b7ac-715d34364465
21/11/10 02:07:31 INFO MemoryStore: MemoryStore started with capacity 5.2 GiB
21/11/10 02:07:31 INFO SparkEnv: Registering OutputCommitCoordinator
21/11/10 02:07:31 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/11/10 02:07:31 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://ms0819.utah.cloudlab.us:4040
21/11/10 02:07:31 INFO SparkContext: Added JAR file:/users/kab076/wQFMSpark/./target/wQFMSpark-1.0-SNAPSHOT-jar-with-dependencies.jar at spark://ms0819.utah.cloudlab.us:34969/jars/wQFMSpark-1.0-SNAPSHOT-jar-with-dependencies.jar with timestamp 1636535250689
21/11/10 02:07:31 INFO SparkContext: Added file file:///users/kab076/wQFMSpark/triplets.soda2103 at spark://ms0819.utah.cloudlab.us:34969/files/triplets.soda2103 with timestamp 1636535250689
21/11/10 02:07:31 INFO Utils: Copying /users/kab076/wQFMSpark/triplets.soda2103 to /tmp/spark-e39cd01f-a30e-4b04-b9e1-2df3d4ede51b/userFiles-82c0f83a-3eb1-4f4a-84e7-16adeaea1cb0/triplets.soda2103
21/11/10 02:07:31 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://node0:7077...
21/11/10 02:07:32 INFO TransportClientFactory: Successfully created connection to node0/10.10.1.1:7077 after 46 ms (0 ms spent in bootstraps)
21/11/10 02:07:32 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211110020732-0040
21/11/10 02:07:32 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211110020732-0040/0 on worker-20211109002414-128.110.217.44-43329 (128.110.217.44:43329) with 16 core(s)
21/11/10 02:07:32 INFO StandaloneSchedulerBackend: Granted executor ID app-20211110020732-0040/0 on hostPort 128.110.217.44:43329 with 16 core(s), 40.0 GiB RAM
21/11/10 02:07:32 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211110020732-0040/1 on worker-20211109002452-128.110.217.51-42171 (128.110.217.51:42171) with 16 core(s)
21/11/10 02:07:32 INFO StandaloneSchedulerBackend: Granted executor ID app-20211110020732-0040/1 on hostPort 128.110.217.51:42171 with 16 core(s), 40.0 GiB RAM
21/11/10 02:07:32 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211110020732-0040/2 on worker-20211109002436-128.110.217.52-35535 (128.110.217.52:35535) with 16 core(s)
21/11/10 02:07:32 INFO StandaloneSchedulerBackend: Granted executor ID app-20211110020732-0040/2 on hostPort 128.110.217.52:35535 with 16 core(s), 40.0 GiB RAM
21/11/10 02:07:32 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33323.
21/11/10 02:07:32 INFO NettyBlockTransferService: Server created on ms0819.utah.cloudlab.us:33323
21/11/10 02:07:32 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/11/10 02:07:32 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211110020732-0040/2 is now RUNNING
21/11/10 02:07:32 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211110020732-0040/0 is now RUNNING
21/11/10 02:07:32 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211110020732-0040/1 is now RUNNING
21/11/10 02:07:32 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, ms0819.utah.cloudlab.us, 33323, None)
21/11/10 02:07:32 INFO BlockManagerMasterEndpoint: Registering block manager ms0819.utah.cloudlab.us:33323 with 5.2 GiB RAM, BlockManagerId(driver, ms0819.utah.cloudlab.us, 33323, None)
21/11/10 02:07:32 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, ms0819.utah.cloudlab.us, 33323, None)
21/11/10 02:07:32 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, ms0819.utah.cloudlab.us, 33323, None)
21/11/10 02:07:32 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
21/11/10 02:07:32 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
================= **** ========== Running wQFM on Spark ============== **** ====================
Final Taxa Table: TaxaTable{TAXA_COUNT=101,
 TAXA_LIST=[72, 97, 81, 90, 91, 92, 93, 94, 95, 96, 98, 99, 82, 83, 84, 85, 86, 87, 88, 89, 9, 73, 74, 75, 76, 77, 78, 79, 8, 80, 51, 70, 67, 68, 69, 7, 71, 52, 53, 54, 55, 56, 57, 58, 59, 6, 60, 61, 62, 63, 64, 65, 66, 33, 34, 35, 36, 37, 38, 39, 4, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 5, 50, 15, 16, 17, 18, 19, 2, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 3, 30, 31, 32, 13, 14, 10, 100, 11, 12, 1, 0],
 TAXA_PARTITION_LIST Size=313}
+---+-------+
|tag|count  |
+---+-------+
|296|330    |
|125|1212   |
|124|3304   |
|307|15     |
|272|7261   |
|232|1102147|
|282|2802   |
|234|135653 |
|15 |10634  |
|132|5913   |
|200|3918   |
|11 |26495  |
|279|2256   |
|138|30096  |
|112|699425 |
|30 |33     |
|113|37061  |
|133|5913   |
|287|150    |
|250|21365  |
+---+-------+
only showing top 20 rows

+-----+-----+---+
|value|count|tag|
+-----+-----+---+
+-----+-----+---+

Number of Partitions by taxaPartition: 144
Number of Data Partitions: 48
Partitioning Tasks to workers ...
21/11/10 02:09:16 WARN TaskSetManager: Lost task 14.0 in stage 17.0 (TID 578) (128.110.217.44 executor 0): java.io.InterruptedIOException: DestHost:destPort ms0819.utah.cloudlab.us:9000 , LocalHost:localPort node0.wqfmspark.ugthesis-pg0.utah.cloudlab.us/128.110.217.44:0. Failed on local exception: java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/128.110.217.44:44930 remote=ms0819.utah.cloudlab.us/128.110.217.44:9000]. 60000 millis timeout left.
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy17.create(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:365)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy18.create(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:276)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1216)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1195)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1133)
	at org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:536)
	at org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:533)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:547)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:474)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)
	at util.HDFSWriter.writeToHDFS(HDFSWriter.java:34)
	at mapper.QuartetToTreeTablePartitionMapper.call(QuartetToTreeTablePartitionMapper.java:44)
	at org.apache.spark.sql.Dataset.$anonfun$mapPartitions$1(Dataset.scala:2820)
	at org.apache.spark.sql.execution.MapPartitionsExec.$anonfun$doExecute$3(objects.scala:195)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1423)
	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1350)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1414)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1237)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/128.110.217.44:44930 remote=ms0819.utah.cloudlab.us/128.110.217.44:9000]. 60000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:557)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1816)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)

21/11/10 02:09:17 WARN TaskSetManager: Lost task 40.0 in stage 17.0 (TID 602) (128.110.217.44 executor 0): java.io.IOException: The client is stopped
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1541)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy17.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:553)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy18.complete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:949)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:907)
	at org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:890)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:845)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:101)
	at sun.nio.cs.StreamEncoder.implClose(StreamEncoder.java:320)
	at sun.nio.cs.StreamEncoder.close(StreamEncoder.java:149)
	at java.io.OutputStreamWriter.close(OutputStreamWriter.java:233)
	at java.io.BufferedWriter.close(BufferedWriter.java:266)
	at util.HDFSWriter.writeToHDFS(HDFSWriter.java:25)
	at mapper.QuartetToTreeTablePartitionMapper.call(QuartetToTreeTablePartitionMapper.java:43)
	at org.apache.spark.sql.Dataset.$anonfun$mapPartitions$1(Dataset.scala:2820)
	at org.apache.spark.sql.execution.MapPartitionsExec.$anonfun$doExecute$3(objects.scala:195)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1423)
	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1350)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1414)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1237)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/11/10 02:09:19 WARN TaskSetManager: Lost task 33.0 in stage 17.0 (TID 595) (128.110.217.51 executor 1): java.nio.channels.ClosedChannelException
	at org.apache.hadoop.hdfs.ExceptionLastSeen.throwException4Close(ExceptionLastSeen.java:73)
	at org.apache.hadoop.hdfs.DFSOutputStream.checkClosed(DFSOutputStream.java:153)
	at org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:105)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:57)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at sun.nio.cs.StreamEncoder.writeBytes(StreamEncoder.java:221)
	at sun.nio.cs.StreamEncoder.implWrite(StreamEncoder.java:282)
	at sun.nio.cs.StreamEncoder.write(StreamEncoder.java:125)
	at java.io.OutputStreamWriter.write(OutputStreamWriter.java:207)
	at java.io.BufferedWriter.flushBuffer(BufferedWriter.java:129)
	at java.io.BufferedWriter.write(BufferedWriter.java:230)
	at java.io.Writer.write(Writer.java:157)
	at util.HDFSWriter.writeToHDFS(HDFSWriter.java:23)
	at mapper.QuartetToTreeTablePartitionMapper.call(QuartetToTreeTablePartitionMapper.java:43)
	at org.apache.spark.sql.Dataset.$anonfun$mapPartitions$1(Dataset.scala:2820)
	at org.apache.spark.sql.execution.MapPartitionsExec.$anonfun$doExecute$3(objects.scala:195)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1423)
	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1350)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1414)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1237)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/11/10 02:11:28 ERROR StandaloneSchedulerBackend: Application has been killed. Reason: Master removed our application: KILLED
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Master removed our application: KILLED
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1079)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1079)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1079)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2445)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2261)
	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:414)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:1029)
	at org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:390)
	at org.apache.spark.sql.Dataset.$anonfun$count$1(Dataset.scala:3006)
	at org.apache.spark.sql.Dataset.$anonfun$count$1$adapted(Dataset.scala:3005)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)
	at org.apache.spark.sql.Dataset.count(Dataset.scala:3005)
	at algorithm.Distributer.runExplained(Distributer.java:96)
	at algorithm.Distributer.partitionDataAndRun(Distributer.java:137)
	at algorithm.Distributer.runFunctions(Distributer.java:32)
	at main.App.runwQFMSpark(App.java:24)
	at main.App.initializeAndRun(App.java:45)
	at main.App.main(App.java:59)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:951)
	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180)
	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203)
	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1039)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1048)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
21/11/10 02:11:28 ERROR Utils: Uncaught exception in thread stop-spark-context
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.deploy.client.StandaloneAppClient.stop(StandaloneAppClient.scala:287)
	at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.org$apache$spark$scheduler$cluster$StandaloneSchedulerBackend$$stop(StandaloneSchedulerBackend.scala:259)
	at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.stop(StandaloneSchedulerBackend.scala:131)
	at org.apache.spark.scheduler.TaskSchedulerImpl.stop(TaskSchedulerImpl.scala:881)
	at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2370)
	at org.apache.spark.SparkContext.$anonfun$stop$12(SparkContext.scala:2069)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1419)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anon$3.run(SparkContext.scala:2018)
Caused by: org.apache.spark.SparkException: Could not find AppClient.
	at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:176)
	at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:144)
	at org.apache.spark.rpc.netty.NettyRpcEnv.askAbortable(NettyRpcEnv.scala:242)
	at org.apache.spark.rpc.netty.NettyRpcEndpointRef.askAbortable(NettyRpcEnv.scala:555)
	at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:559)
	at org.apache.spark.rpc.RpcEndpointRef.ask(RpcEndpointRef.scala:74)
	... 9 more
21/11/10 02:11:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/11/10 02:11:57 INFO SparkContext: Running Spark version 3.1.2
21/11/10 02:11:57 INFO ResourceUtils: ==============================================================
21/11/10 02:11:57 INFO ResourceUtils: No custom resources configured for spark.driver.
21/11/10 02:11:57 INFO ResourceUtils: ==============================================================
21/11/10 02:11:57 INFO SparkContext: Submitted application: wQFMSpark
21/11/10 02:11:57 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 20480, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/11/10 02:11:57 INFO ResourceProfile: Limiting resource is cpu
21/11/10 02:11:57 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/11/10 02:11:57 INFO SecurityManager: Changing view acls to: kab076
21/11/10 02:11:57 INFO SecurityManager: Changing modify acls to: kab076
21/11/10 02:11:57 INFO SecurityManager: Changing view acls groups to: 
21/11/10 02:11:57 INFO SecurityManager: Changing modify acls groups to: 
21/11/10 02:11:57 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(kab076); groups with view permissions: Set(); users  with modify permissions: Set(kab076); groups with modify permissions: Set()
21/11/10 02:11:57 INFO Utils: Successfully started service 'sparkDriver' on port 34907.
21/11/10 02:11:57 INFO SparkEnv: Registering MapOutputTracker
21/11/10 02:11:58 INFO SparkEnv: Registering BlockManagerMaster
21/11/10 02:11:58 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/11/10 02:11:58 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/11/10 02:11:58 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/11/10 02:11:58 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-04e22654-6481-43b4-8095-52601bc1a5a4
21/11/10 02:11:58 INFO MemoryStore: MemoryStore started with capacity 10.5 GiB
21/11/10 02:11:58 INFO SparkEnv: Registering OutputCommitCoordinator
21/11/10 02:11:58 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/11/10 02:11:58 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://ms0819.utah.cloudlab.us:4040
21/11/10 02:11:58 INFO SparkContext: Added JAR file:/users/kab076/wQFMSpark/./target/wQFMSpark-1.0-SNAPSHOT-jar-with-dependencies.jar at spark://ms0819.utah.cloudlab.us:34907/jars/wQFMSpark-1.0-SNAPSHOT-jar-with-dependencies.jar with timestamp 1636535517527
21/11/10 02:11:58 INFO SparkContext: Added file file:///users/kab076/wQFMSpark/triplets.soda2103 at spark://ms0819.utah.cloudlab.us:34907/files/triplets.soda2103 with timestamp 1636535517527
21/11/10 02:11:58 INFO Utils: Copying /users/kab076/wQFMSpark/triplets.soda2103 to /tmp/spark-752a0807-1b4d-4f30-a58d-a4080f5f5403/userFiles-752f5c0a-b544-4527-99ea-b2858926e076/triplets.soda2103
21/11/10 02:11:58 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://node0:7077...
21/11/10 02:11:58 INFO TransportClientFactory: Successfully created connection to node0/10.10.1.1:7077 after 48 ms (0 ms spent in bootstraps)
21/11/10 02:11:58 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211110021158-0041
21/11/10 02:11:58 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211110021158-0041/0 on worker-20211109002414-128.110.217.44-43329 (128.110.217.44:43329) with 16 core(s)
21/11/10 02:11:58 INFO StandaloneSchedulerBackend: Granted executor ID app-20211110021158-0041/0 on hostPort 128.110.217.44:43329 with 16 core(s), 20.0 GiB RAM
21/11/10 02:11:58 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211110021158-0041/1 on worker-20211109002452-128.110.217.51-42171 (128.110.217.51:42171) with 16 core(s)
21/11/10 02:11:59 INFO StandaloneSchedulerBackend: Granted executor ID app-20211110021158-0041/1 on hostPort 128.110.217.51:42171 with 16 core(s), 20.0 GiB RAM
21/11/10 02:11:59 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211110021158-0041/2 on worker-20211109002436-128.110.217.52-35535 (128.110.217.52:35535) with 16 core(s)
21/11/10 02:11:59 INFO StandaloneSchedulerBackend: Granted executor ID app-20211110021158-0041/2 on hostPort 128.110.217.52:35535 with 16 core(s), 20.0 GiB RAM
21/11/10 02:11:59 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33841.
21/11/10 02:11:59 INFO NettyBlockTransferService: Server created on ms0819.utah.cloudlab.us:33841
21/11/10 02:11:59 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/11/10 02:11:59 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211110021158-0041/0 is now RUNNING
21/11/10 02:11:59 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211110021158-0041/2 is now RUNNING
21/11/10 02:11:59 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, ms0819.utah.cloudlab.us, 33841, None)
21/11/10 02:11:59 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211110021158-0041/1 is now RUNNING
21/11/10 02:11:59 INFO BlockManagerMasterEndpoint: Registering block manager ms0819.utah.cloudlab.us:33841 with 10.5 GiB RAM, BlockManagerId(driver, ms0819.utah.cloudlab.us, 33841, None)
21/11/10 02:11:59 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, ms0819.utah.cloudlab.us, 33841, None)
21/11/10 02:11:59 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, ms0819.utah.cloudlab.us, 33841, None)
21/11/10 02:11:59 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
21/11/10 02:11:59 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
================= **** ========== Running wQFM on Spark ============== **** ====================
Final Taxa Table: TaxaTable{TAXA_COUNT=101,
 TAXA_LIST=[72, 97, 81, 90, 91, 92, 93, 94, 95, 96, 98, 99, 82, 83, 84, 85, 86, 87, 88, 89, 9, 73, 74, 75, 76, 77, 78, 79, 8, 80, 51, 70, 67, 68, 69, 7, 71, 52, 53, 54, 55, 56, 57, 58, 59, 6, 60, 61, 62, 63, 64, 65, 66, 10, 18, 29, 3, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 4, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 5, 50, 19, 2, 20, 21, 22, 23, 24, 25, 26, 27, 28, 100, 11, 12, 13, 14, 15, 16, 17, 0, 1],
 TAXA_PARTITION_LIST Size=317}
+---+------+
|tag|count |
+---+------+
|296|15    |
|125|4659  |
|7  |42196 |
|124|1497  |
|307|15    |
|282|672   |
|15 |270618|
|234|308774|
|232|325394|
|11 |58510 |
|279|3817  |
|138|701   |
|112|421426|
|308|15    |
|3  |71363 |
|113|120338|
|287|36    |
|250|60354 |
|139|2640  |
|8  |8408  |
+---+------+
only showing top 20 rows

+-----+-----+---+
|value|count|tag|
+-----+-----+---+
+-----+-----+---+

Number of Partitions by taxaPartition: 125
Number of Data Partitions: 48
Partitioning Tasks to workers ...
Total generated trees: 30
+---------+---+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|support  |tag|tree                                                                                                                                                                                                                                                                                                                                |
+---------+---+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|3.71383E8|235|((86,(((81,76),(75,(73,77))),(((99,96),(92,78)),((80,(94,89)),((84,(74,90)),((95,((97,91),(82,93))),((87,79),(88,83,98,85)))))))),((16,(11,(62,37))),((15,2),((((68,59),(40,12)),((14,(41,17)),(20,(70,(6,(39,69)))))),((23,7),(((13,4),((66,21),((18,65),(42,72)))),(((22,61),((38,60),(9,71))),((67,8),(64,(19,63))))))))));      |
|3.1716E8 |111|((((81,76),(75,77)),(((92,78),(99,96)),((80,(94,89)),((84,(74,90)),(((79,87),((88,83),(98,85))),(95,((97,91),(82,93)))))))),(86,((56,(33,((52,37),(53,47)))),((29,54),((((34,(59,5)),(50,(40,12))),(((45,35),(48,(58,(31,(41,49))))),((46,55),(6,(39,32))))),((36,30),(((42,(43,51)),(28,4)),((27,(38,(44,9))),(57,(3,8))))))))));  |
|1.41169E8|112|((86,((92,(96,99)),((81,73),((80,(94,89)),((84,90),((95,((97,91),(93,82))),(87,((88,83),(85,98))))))))),((47,56,52,53,33,37),(54,((((40,50),(34,(68,(59,5)))),((48,49,58,35,45,41,31),(46,55,(70,(6,(32,(39,69))))))),((36,30,7),((4,((66,(43,51)),(65,(72,42)))),((57,(8,67)),((38,60),(44,(71,9))))))))));                        |
|1.24032E8|237|((((28,4),((51,43,66),(65,(72,42)))),((((60,38),(44,71)),(27,61)),((64,(63,57)),(3,(8,67))))),((7,30,36),((((40,50),(34,(68,(59,5)))),(((45,35),(48,(58,((41,49),(31,25))))),((46,55),(70,(6,(32,(39,69))))))),((54,(26,29)),(((78,(80,(74,(79,82)))),((76,81),(75,(77,73)))),(56,(24,(33,((53,47),(52,(11,(62,37))))))))))));      |
|1.20804E8|10 |((((56,16),(24,((47,53),(52,(11,(62,37)))))),(86,((92,96),((89,100),(90,((88,87),(95,(93,(97,91))))))))),((2,(15,(54,(29,26)))),((((34,(59,5)),(10,(50,(12,40)))),((20,((39,6),(46,55))),((45,(35,14)),(48,(58,((17,25),(49,41))))))),((36,23),(((42,(51,(43,21))),(28,(4,13))),((((38,60),(9,44)),(22,(61,27))),(57,(63,19))))))));|
|1.08655E8|232|(((2,(15,(54,(26,29)))),((((50,12),(34,(68,5))),((20,((46,55),(69,32))),((45,(14,35)),(48,(58,(49,(17,(31,25)))))))),((30,(23,36)),(((13,28),(18,(51,(43,21)))),(((22,27),(44,9)),((19,57),(3,67))))))),(((56,16),(24,(33,((52,11),(53,47))))),(86,((92,(99,96)),((94,89),((84,90),((95,(93,(97,91))),(87,((88,83),(98,85))))))))));|
|1.08655E8|231|(((2,(15,(54,(26,29)))),(((34,12,5,50),((20,((46,55),(70,32))),((45,(14,35)),(48,(58,(49,(17,(31,25)))))))),((7,(30,(23,36))),(((28,13),(18,(51,(43,21)))),((3,(57,19)),((27,22),(44,(71,9)))))))),(((56,16),(24,(33,((52,11),(53,47))))),(86,((92,(96,99)),((94,89),((84,90),((95,(93,(97,91))),(87,((83,88),(85,98))))))))));     |
|1.03245E8|234|((((28,13),(18,(51,(43,21)))),(((9,44),(22,(27,61))),(3,(57,(63,19))))),((30,(23,36)),(((5,50,34,12),((20,(46,55,32)),((45,(14,35)),(48,(58,(49,(17,(31,25)))))))),((2,(15,(54,(26,29)))),((86,((92,(96,99)),((94,89),((84,90),((95,(93,(97,91))),(87,((83,88),(85,98)))))))),((56,16),(24,(33,((52,(62,11)),(53,47))))))))));      |
|9.5945E7 |117|((86,((81,76,77),(((99,96),(92,78)),((80,(94,89)),((84,90),(((79,87),(88,83,98,85)),(95,((97,91),(82,93))))))))),(((24,(52,(47,53))),(16,56)),((26,29,54),((((59,5),(50,40)),((20,((46,55),(39,6))),(45,(48,(58,((31,25),(41,49))))))),((23,30),(((28,4),(42,(51,(43,21)))),((57,(3,8)),((44,9,60),(22,(61,27))))))))));            |
|9.1764E7 |233|((((13,28),((18,65),(66,(51,(43,21))))),(((22,27),(9,44)),(3,(64,(57,19))))),((30,(36,23)),(((12,5,50,34),((20,(46,32,55)),((45,(35,14)),(48,(58,(49,(17,(25,31)))))))),((2,(15,(54,(29,26)))),(((56,16),(24,(33,((52,11),(53,47))))),(86,((92,(96,99)),((94,89),((84,90),((95,(93,(97,91))),(87,((88,83),(85,98)))))))))))));      |
|9.076E7  |118|((((4,28),((66,(51,(43,21))),((72,42),(18,65)))),((((38,60),(71,44)),(22,(61,27))),((3,67),(64,(57,(63,19)))))),((7,(36,23,30)),(((2,(29,54,26)),((75,73,74),((56,16),(24,(33,((53,47),(52,(62,37)))))))),(((40,50),(34,(68,(59,5)))),(((35,45),(48,(58,((49,41),(17,(25,31)))))),(20,(46,55,(70,(6,(32,(39,69)))))))))));          |
|6.4834E7 |238|((86,((75,73,76,77,81),((99,92,78,96),((94,89,80),((84,74,90),(88,83,98,85,91,87,93,79,82,95,97)))))),((24,(33,(37,62,11))),((26,29),(((40,(68,34)),((35,(58,25,31,41)),(70,(32,(39,69))))),((7,(30,(23,36))),(((28,4),(66,(72,42,65))),(((27,61),(38,(9,71))),((63,64),(3,(67,8))))))))));                                         |
|6.4758E7 |116|((((56,16),(33,((53,47),(52,(62,37))))),(86,(94,88,95,89,96,97,90,98,91,99,92,93,78,79,80,81,82,76,77,83,84,85,87))),((54,2),((((59,5,34),(40,50)),(((46,55),(6,(32,39))),((45,35),(48,(58,(17,(41,49))))))),(36,((4,((51,43),(18,42))),((61,((60,38),(9,44))),(8,(57,(63,19)))))))));                                              |
|6.1863E7 |236|(((30,(36,23)),((((12,50),(34,(59,5))),((20,((46,55),(32,6))),((45,(35,14)),(48,(58,(49,(17,(25,31)))))))),((2,(15,(54,(29,26)))),(((56,16),(24,(33,((52,11),(53,47))))),(86,(97,98,99,88,89,90,91,92,93,83,84,85,87,94,95,96)))))),(((13,28),(18,(51,(43,21)))),(((22,27),(60,(9,44))),(3,(57,19)))));                             |
|5.8795E7 |251|(((76,(75,77,73)),(((96,99),(92,78)),(81,((80,100,(94,89)),((84,74,90),((95,((97,91),(93,82))),((87,79),((88,83),(85,98))))))))),(86,((0,((24,(33,11)),(1,16))),((2,(15,(29,26))),(((34,(10,12)),((20,(70,(32,69))),((35,14),(17,(25,31))))),((7,(30,(36,23))),(((13,28),(21,(18,72))),(((22,27),(71,9)),(19,(3,8))))))))));        |
|5.0784E7 |249|((((81,76),(75,(73,77))),((78,(99,96)),((94,(100,80)),((84,74),((95,(82,97)),((79,87),(83,(98,85)))))))),(86,((0,(54,((7,((4,((66,(43,51)),(65,(42,72)))),((61,((38,60),(44,71))),((67,8),(64,(57,63)))))),(((10,(50,40)),(68,(59,5))),((45,(48,(58,(41,49)))),((46,55),(70,(6,(39,69))))))))),((56,1),((53,47),(52,(37,62)))))));  |
|4.2245E7 |114|((((99,96),(92,78)),((81,75,76,77),((80,(94,89)),((84,(74,90)),(((79,87),(88,83,98,85)),(95,((97,91),(82,93)))))))),((47,56,52,53,33,(37,62)),((54,(86,(36,30))),((45,39,31,58,34,35,40,41,59,32,6,46,48,49,5,50,55),((42,(4,(43,51))),((61,(44,9,38,60)),(8,(64,(57,63)))))))));                                                   |
|4.0336E7 |113|((86,(78,(((76,81),(75,(77,73))),((80,89),((74,84),(82,((79,87),(85,(83,88))))))))),((56,(33,((53,47),(52,(62,37))))),(54,((40,45,41,70,46,48,49,5,50,55,31,32,34,58,35,69,59,6,39,68),((7,30,36),((4,(42,51,43,65,72,66)),(((8,67),(64,(63,57))),(61,((60,38),(44,(71,9)))))))))));                                                |
|3.785E7  |252|((0,((2,(15,(54,(26,29)))),(((23,36,30),(((28,(13,4)),((42,(18,65)),(66,(51,(43,21))))),(((44,38,60),(22,(61,27))),((3,67),(64,(57,(19,63))))))),(((10,(50,(40,12))),(34,(68,59,5))),((20,((46,55),(6,(39,32)))),((45,(14,35)),(48,(58,((41,49),(25,17,31)))))))))),((56,(16,1)),(24,(33,((52,(11,(37,62))),(47,53))))));           |
|3.5536E7 |119|(((2,(26,29)),(((34,68),((20,(70,32,69)),(35,(17,(31,25))))),((7,36,23,30),((28,((66,21),(18,65,72))),((71,((38,9),(27,22))),((63,64,19),(3,(8,67)))))))),((16,(24,(33,62,37))),(86,(75,94,88,95,89,96,97,90,98,91,99,92,93,78,79,80,81,73,82,74,76,77,83,84,85,87))));                                                             |
+---------+---+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
only showing top 20 rows

All partitioned Tasks Complete, Elapsed time: 389111
Final tree (((2,(26,29)),(((34,68),((20,(70,32,69)),(35,(17,(31,25))))),((7,36,23,30),((28,((66,21),(18,65,72))),((71,((38,9),(27,22))),((63,64,19),(3,(8,67)))))))),((16,(24,(33,62,37))),(86,(75,94,88,95,89,96,97,90,98,91,99,92,93,78,79,80,81,73,82,74,76,77,83,84,85,87))));
distributedRunTree: (((2,(26,29)),(((34,68),((20,(70,32,69)),(35,(17,(31,25))))),((7,36,23,30),((28,((66,21),(18,65,72))),((71,((38,9),(27,22))),((63,64,19),(3,(8,67)))))))),((16,(24,(33,62,37))),(86,(75,94,88,95,89,96,97,90,98,91,99,92,93,78,79,80,81,73,82,74,76,77,83,84,85,87))));

Time taken = 452906 ms ==> 7 minutes and 32 seconds.
================= **** ======================== **** ====================
